# api/endpoints/intelligence.py - å®Œæ•´ä¿®å¤ç‰ˆ
from __future__ import annotations

import json
import html
import asyncio
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
import time
import csv
import json
import io
from datetime import datetime

# FastAPI æ ¸å¿ƒå¯¼å…¥
from fastapi import APIRouter, Depends, HTTPException, Query, Body, Form
from starlette.requests import Request
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.templating import Jinja2Templates

# SQLAlchemy å¯¼å…¥
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete, and_, or_, func, text
from sqlalchemy.orm import selectinload

# é¡¹ç›®å†…éƒ¨å¯¼å…¥
from core.database import get_db, get_ai_processing_db
from models.intelligence_models import Intelligence, IntelligenceSource
from models.base_models import Topic, Source
from schemas.intelligence_schemas import (
    IntelligenceCreate, IntelligenceUpdate, IntelligenceResponse,
    IntelligenceFilter, IntelligenceScore, MergeRequest
)

# åˆ›å»ºè·¯ç”±å™¨
api_router = APIRouter(prefix="/api/intelligence", tags=["intelligence"])
pages_router = APIRouter(prefix="/intelligence", tags=["intelligence_pages"])

# é…ç½®æ¨¡æ¿ç›®å½•
templates = Jinja2Templates(directory="templates")


# ===== APIè·¯ç”± =====
def safe_format_datetime(dt_value):
    """å®‰å…¨åœ°æ ¼å¼åŒ–æ—¶é—´å€¼"""
    if dt_value is None:
        return ""
    try:
        if isinstance(dt_value, str):
            return dt_value
        elif hasattr(dt_value, 'isoformat'):
            return dt_value.isoformat()
        else:
            return str(dt_value)
    except Exception:
        return str(dt_value) if dt_value else ""


@api_router.get("/export")
async def export_intelligence(
        db: AsyncSession = Depends(get_db),
        format: str = Query("csv", description="å¯¼å‡ºæ ¼å¼: csv, json, excel"),
        export_scope: str = Query("selected", description="å¯¼å‡ºèŒƒå›´: selected, filtered, all"),
        intelligence_ids: Optional[str] = Query(None, description="é€‰ä¸­çš„æƒ…æŠ¥IDåˆ—è¡¨(é€—å·åˆ†éš”)"),
        # ç­›é€‰å‚æ•°
        title: Optional[str] = Query(None),
        topic: Optional[str] = Query(None),
        quality: Optional[str] = Query(None),
        min_score: Optional[float] = Query(None),
        max_score: Optional[float] = Query(None),
        news_start_date: Optional[str] = Query(None),
        news_end_date: Optional[str] = Query(None),
        start_date: Optional[str] = Query(None),
        end_date: Optional[str] = Query(None)
):
    """å¯¼å‡ºæƒ…æŠ¥æ•°æ®"""
    try:
        print(f"å¯¼å‡ºè¯·æ±‚: format={format}, scope={export_scope}")

        # æ ¹æ®å¯¼å‡ºèŒƒå›´æ„å»ºæŸ¥è¯¢
        data_to_export = []

        if export_scope == "selected" and intelligence_ids:
            # å¯¼å‡ºé€‰ä¸­çš„æƒ…æŠ¥
            ids = [int(id.strip()) for id in intelligence_ids.split(',') if id.strip()]
            if not ids:
                raise HTTPException(status_code=400, detail="æœªæä¾›æœ‰æ•ˆçš„æƒ…æŠ¥ID")

            from sqlalchemy import text
            placeholders = ','.join([f':id_{j}' for j in range(len(ids))])
            params = {f'id_{j}': ids[j] for j in range(len(ids))}

            # æ·»åŠ  score_dimensions å­—æ®µ
            query_sql = f"""
                SELECT i.id, i.title, i.summary, i.topic, i.news_time, i.collect_time, 
                       i.ai_score, i.score_dimensions, i.quality_status, i.is_merged, i.merged_count,
                       s.url, s.domain
                FROM intelligence i
                LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
                WHERE i.id IN ({placeholders})
                ORDER BY i.news_time DESC
            """

            result = await db.execute(text(query_sql), params)
            rows = result.fetchall()

        elif export_scope == "filtered":
            # å¯¼å‡ºç­›é€‰ç»“æœ
            where_conditions = []
            params = {}

            if title and title.strip():
                where_conditions.append("i.title LIKE :title")
                params['title'] = f"%{title.strip()}%"

            if topic and topic.strip():
                where_conditions.append("i.topic LIKE :topic")
                params['topic'] = f"%{topic.strip()}%"

            if quality and quality.strip():
                where_conditions.append("i.quality_status = :quality")
                params['quality'] = quality.strip()

            if min_score is not None:
                where_conditions.append("i.ai_score >= :min_score")
                params['min_score'] = float(min_score)

            if max_score is not None:
                where_conditions.append("i.ai_score <= :max_score")
                params['max_score'] = float(max_score)

            # æ—¶é—´ç­›é€‰
            if news_start_date:
                try:
                    from dateutil import parser
                    start_dt = parser.parse(news_start_date)
                    where_conditions.append("i.news_time >= :news_start_date")
                    params['news_start_date'] = start_dt
                except:
                    pass

            if news_end_date:
                try:
                    from dateutil import parser
                    end_dt = parser.parse(news_end_date)
                    where_conditions.append("i.news_time <= :news_end_date")
                    params['news_end_date'] = end_dt
                except:
                    pass

            # æ„å»ºWHEREå­å¥
            where_clause = ""
            if where_conditions:
                where_clause = "WHERE " + " AND ".join(where_conditions)

            # æ·»åŠ  score_dimensions å­—æ®µ
            query_sql = f"""
                SELECT i.id, i.title, i.summary, i.topic, i.news_time, i.collect_time, 
                       i.ai_score, i.score_dimensions, i.quality_status, i.is_merged, i.merged_count,
                       s.url, s.domain
                FROM intelligence i
                LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
                {where_clause}
                ORDER BY i.news_time DESC NULLS LAST
                LIMIT 10000
            """

            result = await db.execute(text(query_sql), params)
            rows = result.fetchall()

        else:  # export_scope == "all"
            # å¯¼å‡ºå…¨éƒ¨æ•°æ®
            query_sql = """
                SELECT i.id, i.title, i.summary, i.topic, i.news_time, i.collect_time, 
                       i.ai_score, i.score_dimensions, i.quality_status, i.is_merged, i.merged_count,
                       s.url, s.domain
                FROM intelligence i
                LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
                ORDER BY i.news_time DESC NULLS LAST
                LIMIT 50000
            """

            result = await db.execute(text(query_sql), {})
            rows = result.fetchall()

        # å¤„ç†æŸ¥è¯¢ç»“æœ
        intelligence_dict = {}
        for row in rows:
            intel_id = row.id
            if intel_id not in intelligence_dict:
                # è§£æè¯„åˆ†æ•°æ®
                dimensions = {}
                if row.score_dimensions:
                    try:
                        import json
                        if isinstance(row.score_dimensions, str):
                            dimensions = json.loads(row.score_dimensions)
                        else:
                            dimensions = row.score_dimensions
                        print(f"æˆåŠŸè§£ææƒ…æŠ¥ {intel_id} çš„è¯„åˆ†æ•°æ®: {dimensions}")
                    except Exception as json_error:
                        print(f"JSONè§£æå¤±è´¥ {intel_id}: {json_error}")
                        dimensions = {}

                intelligence_dict[intel_id] = {
                    'id': row.id,
                    'title': row.title,
                    'summary': row.summary or '',
                    'topic': row.topic or '',
                    'category': 'å‰æ²¿èµ„è®¯',  # é»˜è®¤ç±»åˆ«
                    'news_time': safe_format_datetime(row.news_time),
                    'collect_time': safe_format_datetime(row.collect_time),
                    'ai_score': float(row.ai_score or 0),
                    'dimensions': dimensions,  # æ·»åŠ è§£æåçš„è¯„åˆ†æ•°æ®
                    'quality_status': row.quality_status or 'pending',
                    'is_merged': bool(row.is_merged),
                    'merged_count': int(row.merged_count or 0),
                    'sources': []
                }

            # æ·»åŠ æ¥æºä¿¡æ¯
            if row.url:
                intelligence_dict[intel_id]['sources'].append({
                    'url': row.url,
                    'domain': row.domain or ''
                })

        data_to_export = list(intelligence_dict.values())

        print(f"å‡†å¤‡å¯¼å‡º {len(data_to_export)} æ¡æƒ…æŠ¥")

        # æ ¹æ®æ ¼å¼ç”Ÿæˆç›¸åº”çš„å“åº”
        if format.lower() == 'csv':
            return export_as_csv(data_to_export)
        elif format.lower() == 'json':
            return export_as_json(data_to_export)
        elif format.lower() == 'excel':
            return export_as_excel(data_to_export)
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼")

    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")


def export_as_csv(data):
    """å¯¼å‡ºä¸ºCSVæ ¼å¼ - æ”¯æŒæ–°æ ‡é¢˜"""
    output = io.StringIO()
    writer = csv.writer(output)

    # å†™å…¥è¡¨å¤´ - æ·»åŠ æ–°æ ‡é¢˜å­—æ®µ
    headers = [
        'ID', 'åŸæ ‡é¢˜', 'æ–°æ ‡é¢˜', 'æ‘˜è¦', 'è®®é¢˜', 'ç±»åˆ«', 'æ–°é—»æ—¶é—´', 'æ”¶é›†æ—¶é—´',
        'AIè¯„åˆ†', 'æˆ˜ç•¥ç›¸å…³æ€§è¯„åˆ†', 'è¡Œä¸šå½±å“åŠ›è¯„åˆ†', 'æ—¶æ•ˆæ€§ç´§è¿«æ€§è¯„åˆ†',
        'ä¸šåŠ¡æœºä¼šé£é™©å¼ºåº¦è¯„åˆ†', 'å¯æ“ä½œæ€§è¯„åˆ†', 'è¯„åˆ†ç»†åˆ™æ±‡æ€»',
        'è´¨é‡çŠ¶æ€', 'æ˜¯å¦åˆå¹¶', 'åˆå¹¶æ•°é‡', 'æ¥æºé“¾æ¥', 'æ¥æºåŸŸå'
    ]
    writer.writerow(headers)

    # å†™å…¥æ•°æ®
    for item in data:
        print(f"å¤„ç†å¯¼å‡ºæ•°æ® {item['id']}: dimensions = {item.get('dimensions', {})}")

        # å¤„ç†å¤šä¸ªæ¥æº
        sources_urls = []
        sources_domains = []

        for source in item.get('sources', []):
            sources_urls.append(source.get('url', ''))
            sources_domains.append(source.get('domain', ''))

        # å¤„ç†æ–°çš„è¯„åˆ†ç»´åº¦
        dimensions = item.get('dimensions', {})
        score_details = format_score_details(dimensions)

        # æå–å„ç»´åº¦è¯„åˆ†
        strategic_score = 0
        industry_score = 0
        timeliness_score = 0
        business_score = 0
        actionability_score = 0

        if dimensions:
            strategic_data = dimensions.get('æˆ˜ç•¥ç›¸å…³æ€§', {})
            if isinstance(strategic_data, dict):
                strategic_score = strategic_data.get('åˆ†æ•°', 0)

            industry_data = dimensions.get('è¡Œä¸šå½±å“åŠ›', {})
            if isinstance(industry_data, dict):
                industry_score = industry_data.get('åˆ†æ•°', 0)

            timeliness_data = dimensions.get('æ—¶æ•ˆæ€§ç´§è¿«æ€§', {})
            if isinstance(timeliness_data, dict):
                timeliness_score = timeliness_data.get('åˆ†æ•°', 0)

            business_data = dimensions.get('ä¸šåŠ¡æœºä¼šé£é™©å¼ºåº¦', {})
            if isinstance(business_data, dict):
                business_score = business_data.get('åˆ†æ•°', 0)

            actionability_data = dimensions.get('å¯æ“ä½œæ€§', {})
            if isinstance(actionability_data, dict):
                actionability_score = actionability_data.get('åˆ†æ•°', 0)

        row = [
            item.get('id', ''),
            item.get('original_title', item.get('title', '')),  # åŸæ ‡é¢˜
            item.get('new_title', ''),  # æ–°æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©º
            item.get('summary', ''),
            item.get('topic', ''),
            item.get('category', 'å‰æ²¿èµ„è®¯'),
            item.get('news_time', ''),
            item.get('collect_time', ''),
            item.get('ai_score', 0),
            strategic_score,
            industry_score,
            timeliness_score,
            business_score,
            actionability_score,
            score_details,
            item.get('quality_status', ''),
            'æ˜¯' if item.get('is_merged') else 'å¦',
            item.get('merged_count', 0),
            '; '.join(sources_urls),
            '; '.join(sources_domains)
        ]
        writer.writerow(row)

    output.seek(0)

    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"intelligence_export_{timestamp}.csv"

    # è¿”å›å“åº”
    response = StreamingResponse(
        io.BytesIO(output.getvalue().encode('utf-8-sig')),
        media_type='text/csv',
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

    return response


def export_as_json(data):
    """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
    # ä¸ºæ¯ä¸ªé¡¹ç›®æ·»åŠ æ ¼å¼åŒ–çš„è¯„åˆ†ç»†åˆ™
    for item in data:
        item['formatted_score_details'] = format_score_details(item.get('dimensions', {}))

    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"intelligence_export_{timestamp}.json"

    # æ„å»ºå¯¼å‡ºæ•°æ®ç»“æ„
    export_data = {
        "export_info": {
            "timestamp": datetime.now().isoformat(),
            "total_records": len(data),
            "format": "JSON"
        },
        "data": data
    }

    json_content = json.dumps(export_data, ensure_ascii=False, indent=2)

    response = StreamingResponse(
        io.BytesIO(json_content.encode('utf-8')),
        media_type='application/json',
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

    return response


def export_as_excel(data):
    """å¯¼å‡ºä¸ºExcelæ ¼å¼"""
    output = io.StringIO()
    writer = csv.writer(output)

    # å†™å…¥è¡¨å¤´
    headers = [
        'ID', 'æ ‡é¢˜', 'æ‘˜è¦', 'è®®é¢˜', 'ç±»åˆ«', 'æ–°é—»æ—¶é—´', 'æ”¶é›†æ—¶é—´',
        'AIè¯„åˆ†', 'è¯„åˆ†ç»†åˆ™', 'è´¨é‡çŠ¶æ€', 'æ˜¯å¦åˆå¹¶', 'åˆå¹¶æ•°é‡', 'æ¥æºé“¾æ¥æ•°é‡'
    ]
    writer.writerow(headers)

    # å†™å…¥æ•°æ®
    for item in data:
        score_details = format_score_details(item.get('dimensions', {}))

        row = [
            item.get('id', ''),
            item.get('title', ''),
            item.get('summary', ''),
            item.get('topic', ''),
            item.get('category', 'å‰æ²¿èµ„è®¯'),
            item.get('news_time', ''),
            item.get('collect_time', ''),
            item.get('ai_score', 0),
            score_details,
            item.get('quality_status', ''),
            'æ˜¯' if item.get('is_merged') else 'å¦',
            item.get('merged_count', 0),
            len(item.get('sources', []))
        ]
        writer.writerow(row)

    output.seek(0)

    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"intelligence_export_{timestamp}.csv"

    response = StreamingResponse(
        io.BytesIO(output.getvalue().encode('utf-8-sig')),
        media_type='application/vnd.ms-excel',
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

    return response


def format_score_details(dimensions):
    """æ ¼å¼åŒ–è¯„åˆ†ç»†åˆ™ä¸ºå•ä¸ªå­—ç¬¦ä¸² - æ”¯æŒæ–°çš„è¯„åˆ†ç»´åº¦"""
    if not dimensions or not isinstance(dimensions, dict):
        return "æš‚æ— è¯„åˆ†ç»†åˆ™"

    print(f"æ ¼å¼åŒ–è¯„åˆ†ç»†åˆ™ï¼Œè¾“å…¥: {dimensions}")

    details = []

    # å¤„ç†æ–°çš„è¯„åˆ†ç»´åº¦
    dimension_mapping = {
        "æˆ˜ç•¥ç›¸å…³æ€§": "strategic_relevance",
        "è¡Œä¸šå½±å“åŠ›": "industry_impact",
        "æ—¶æ•ˆæ€§ç´§è¿«æ€§": "timeliness_urgency",
        "ä¸šåŠ¡æœºä¼šé£é™©å¼ºåº¦": "business_opportunity_risk",
        "å¯æ“ä½œæ€§": "actionability"
    }

    for chinese_name, english_key in dimension_mapping.items():
        # ä¼˜å…ˆä½¿ç”¨ä¸­æ–‡é”®ï¼Œå…¶æ¬¡ä½¿ç”¨è‹±æ–‡é”®
        dimension_data = dimensions.get(chinese_name, dimensions.get(english_key, {}))

        if isinstance(dimension_data, dict):
            score = dimension_data.get('åˆ†æ•°', dimension_data.get('score', 0))
            reason = dimension_data.get('ç†ç”±', dimension_data.get('reason', '')).strip()

            if reason:
                details.append(f"{chinese_name}({score}/10): {reason}")

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è¯„åˆ†ç»†åˆ™ï¼Œè¿”å›é»˜è®¤å€¼
    if not details:
        print(f"æœªæ‰¾åˆ°æœ‰æ•ˆè¯„åˆ†ç»†åˆ™ï¼ŒåŸå§‹æ•°æ®: {dimensions}")
        return "æš‚æ— è¯„åˆ†ç»†åˆ™"

    result = '; '.join(details)
    print(f"æ ¼å¼åŒ–ç»“æœ: {result}")
    return result


def build_score_tooltip(dimensions):
    """æ„å»ºAIè¯„åˆ†tooltip - æ”¯æŒæ–°è¯„åˆ†ç»´åº¦"""
    tooltip_content = "æš‚æ— AIè¯„åˆ†è¯¦æƒ…"

    if dimensions:
        tooltip_parts = []

        # æ–°çš„è¯„åˆ†ç»´åº¦
        dimension_configs = [
            ("æˆ˜ç•¥ç›¸å…³æ€§", "strategic_relevance"),
            ("è¡Œä¸šå½±å“åŠ›", "industry_impact"),
            ("æ—¶æ•ˆæ€§ç´§è¿«æ€§", "timeliness_urgency"),
            ("ä¸šåŠ¡æœºä¼šé£é™©å¼ºåº¦", "business_opportunity_risk"),
            ("å¯æ“ä½œæ€§", "actionability")
        ]

        for chinese_name, english_key in dimension_configs:
            dimension_data = dimensions.get(chinese_name, dimensions.get(english_key, {}))

            if isinstance(dimension_data, dict):
                score_val = dimension_data.get('åˆ†æ•°', dimension_data.get('score', 0))
                reason = dimension_data.get('ç†ç”±', dimension_data.get('reason', ''))

                # é™åˆ¶ç†ç”±é•¿åº¦é¿å…tooltipè¿‡é•¿
                if len(reason) > 100:
                    reason = reason[:100] + '...'

                if reason:
                    tooltip_parts.append(f"{chinese_name}: {score_val}/10 - {reason}")

        if tooltip_parts:
            tooltip_content = "\\n".join(tooltip_parts)

    return html.escape(tooltip_content).replace('"', '&quot;').replace("'", '&#39;')


@api_router.get("/export-template")
async def download_template():
    """ä¸‹è½½å¯¼å…¥æ¨¡æ¿ - åŒ…å«ç±»åˆ«å’Œè¯„åˆ†ç»†åˆ™å­—æ®µ"""
    try:
        output = io.StringIO()
        writer = csv.writer(output)

        # æ¨¡æ¿è¡¨å¤´ - åŒ…å«ç±»åˆ«å­—æ®µ
        headers = [
            'title', 'summary', 'topic', 'category', 'news_time',
            'source_url', 'source_title', 'quality_status'
        ]
        writer.writerow(headers)

        # ç¤ºä¾‹æ•°æ®
        example_row = [
            'ç¤ºä¾‹æ–°é—»æ ‡é¢˜',
            'è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ‘˜è¦ï¼Œæè¿°æ–°é—»çš„ä¸»è¦å†…å®¹',
            'ESG',
            'å‰æ²¿èµ„è®¯',  # æ·»åŠ ç±»åˆ«ç¤ºä¾‹
            '2024-01-15 10:30:00',
            'https://example.com/news/123',
            'ç¤ºä¾‹æ–°é—»ç½‘ç«™',
            'pending'
        ]
        writer.writerow(example_row)

        output.seek(0)

        response = StreamingResponse(
            io.BytesIO(output.getvalue().encode('utf-8-sig')),
            media_type='text/csv',
            headers={"Content-Disposition": "attachment; filename=intelligence_import_template.csv"}
        )

        return response

    except Exception as e:
        print(f"âŒ æ¨¡æ¿ä¸‹è½½å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¨¡æ¿ä¸‹è½½å¤±è´¥: {str(e)}")


@api_router.post("/batch-extract-dates")
async def batch_extract_dates(
        db: AsyncSession = Depends(get_db),
        request_data: dict = Body(...)
):
    """æ‰¹é‡ä¸ºç¼ºå°‘æ—¥æœŸçš„æ–‡ç« æå–æ—¥æœŸ - SQLiteå…¼å®¹ç‰ˆ"""
    try:
        intelligence_ids = request_data.get("intelligence_ids", [])
        date_selectors = request_data.get("date_selectors", [])

        if not intelligence_ids:
            return {"status": "error", "message": "è¯·æä¾›è¦å¤„ç†çš„æƒ…æŠ¥IDåˆ—è¡¨"}

        print(f"ğŸ•’ å¼€å§‹æ‰¹é‡æ—¥æœŸæå–: {len(intelligence_ids)} æ¡æƒ…æŠ¥")

        # ä¿®å¤ï¼šä½¿ç”¨å‘½åå‚æ•°è€Œä¸æ˜¯ä½ç½®å‚æ•°
        from sqlalchemy import text

        # æ„å»ºæŸ¥è¯¢ - åˆ†æ‰¹å¤„ç†å¤§é‡ID
        articles_data_all = []
        batch_size = 100  # SQLiteå¯¹INå­å¥æœ‰é™åˆ¶

        for i in range(0, len(intelligence_ids), batch_size):
            batch_ids = intelligence_ids[i:i + batch_size]

            # ä¿®å¤ï¼šæ„å»ºå‘½åå‚æ•°
            placeholders = ','.join([f':id_{j}' for j in range(len(batch_ids))])
            params = {f'id_{j}': batch_ids[j] for j in range(len(batch_ids))}

            query_sql = f"""
                SELECT i.id, i.title, i.news_time, s.url, s.title as source_title
                FROM intelligence i
                LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
                WHERE i.id IN ({placeholders})
            """

            # ä½¿ç”¨å­—å…¸å‚æ•°è€Œä¸æ˜¯å…ƒç»„
            result = await db.execute(text(query_sql), params)
            articles_data_all.extend(result.fetchall())

        if not articles_data_all:
            return {"status": "error", "message": "æœªæ‰¾åˆ°æŒ‡å®šçš„æƒ…æŠ¥"}

        # è½¬æ¢ä¸ºå¤„ç†æ ¼å¼
        articles = []
        for row in articles_data_all:
            articles.append({
                'id': row.id,
                'title': row.title,
                'news_time': row.news_time,
                'url': row.url
            })

        # è°ƒç”¨æ‰¹é‡æ—¥æœŸæå–åŠŸèƒ½
        from services.ai_service import batch_extract_missing_dates

        extraction_results = await batch_extract_missing_dates(articles, date_selectors)

        # æ›´æ–°æ•°æ®åº“ä¸­æˆåŠŸæå–åˆ°æ—¥æœŸçš„è®°å½•
        updated_count = 0
        successful_results = []

        for result in extraction_results:
            if result['success'] and result.get('extracted_date'):
                try:
                    await db.execute(
                        text("""
                            UPDATE intelligence 
                            SET news_time = :news_time, 
                                update_time = :update_time
                            WHERE id = :id
                        """),
                        {
                            "id": result['id'],
                            "news_time": result['extracted_date'],
                            "update_time": datetime.now().isoformat()
                        }
                    )
                    updated_count += 1
                    successful_results.append(result)
                    print(f"âœ… å·²æ›´æ–°æƒ…æŠ¥ {result['id']} çš„æ—¥æœŸ: {result['extracted_date']}")
                except Exception as e:
                    print(f"âŒ æ›´æ–°æƒ…æŠ¥ {result['id']} å¤±è´¥: {e}")
                    result['success'] = False
                    result['error'] = str(e)

        await db.commit()

        total_processed = len(extraction_results)
        success_count = len(successful_results)

        print(f"ğŸ‰ æ‰¹é‡æ—¥æœŸæå–å®Œæˆ: æˆåŠŸ {success_count}/{total_processed} æ¡")

        return {
            "status": "success",
            "message": f"æ‰¹é‡æ—¥æœŸæå–å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {total_processed - success_count} æ¡",
            "total_processed": total_processed,
            "success_count": success_count,
            "updated_count": updated_count,
            "results": extraction_results,
            "successful_extractions": successful_results
        }

    except Exception as e:
        print(f"âŒ æ‰¹é‡æ—¥æœŸæå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        await db.rollback()
        return {"status": "error", "message": f"æ‰¹é‡æ—¥æœŸæå–å¤±è´¥: {str(e)}"}


@api_router.get("/missing-dates")
async def get_articles_missing_dates(
        db: AsyncSession = Depends(get_db),
        limit: int = Query(100, ge=1, le=500, description="é™åˆ¶è¿”å›æ•°é‡"),
        topic: Optional[str] = Query(None, description="æŒ‰è®®é¢˜ç­›é€‰")
):
    """è·å–ç¼ºå°‘æ—¥æœŸçš„æ–‡ç« åˆ—è¡¨ - SQLiteå…¼å®¹ç‰ˆ"""
    try:
        print(f"æ”¶åˆ°è¯·æ±‚å‚æ•°: limit={limit}, topic={topic}")

        from sqlalchemy import text

        # SQLiteå…¼å®¹çš„æŸ¥è¯¢
        query_sql = """
            SELECT i.id, i.title, i.topic, i.collect_time, s.url, s.domain
            FROM intelligence i
            LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
            WHERE (i.news_time IS NULL OR i.news_time = '')
        """

        params = {'limit': limit}  # å§‹ç»ˆä½¿ç”¨å­—å…¸å‚æ•°

        # æ·»åŠ topicç­›é€‰æ¡ä»¶
        if topic and topic.strip():
            query_sql += " AND i.topic LIKE :topic"
            params['topic'] = f"%{topic.strip()}%"

        # æ·»åŠ æ’åºå’Œé™åˆ¶
        query_sql += " ORDER BY i.collect_time DESC LIMIT :limit"

        print(f"æ‰§è¡ŒSQL: {query_sql}")
        print(f"SQLå‚æ•°: {params}")

        result = await db.execute(text(query_sql), params)
        rows = result.fetchall()

        articles = []
        seen_ids = set()  # å»é‡

        for row in rows:
            if row.id not in seen_ids:
                seen_ids.add(row.id)
                articles.append({
                    "id": row.id,
                    "title": row.title,
                    "topic": row.topic or "æœªåˆ†ç±»",
                    "collect_time": row.collect_time.isoformat() if row.collect_time else None,
                    "url": row.url or "",
                    "domain": row.domain or ""
                })

        print(f"æ‰¾åˆ° {len(articles)} æ¡ç¼ºå°‘æ—¥æœŸçš„æ–‡ç« ")

        return {
            "status": "success",
            "total": len(articles),
            "articles": articles
        }

    except Exception as e:
        print(f"æŸ¥è¯¢ç¼ºå°‘æ—¥æœŸçš„æ–‡ç« å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "message": str(e)}
        return {"status": "error", "message": str(e)}


@api_router.post("/test-date-extraction")
async def test_date_extraction(
        request_data: dict = Body(...)
):
    """æµ‹è¯•æ—¥æœŸæå–åŠŸèƒ½"""
    try:
        url = request_data.get("url")
        date_selectors = request_data.get("date_selectors", [])

        if not url:
            return {"status": "error", "message": "è¯·æä¾›è¦æµ‹è¯•çš„URL"}

        print(f"ğŸ§ª æµ‹è¯•æ—¥æœŸæå–: {url}")

        from services.ai_service import extract_date_from_url

        result = await extract_date_from_url(url, date_selectors)

        return {
            "status": "success",
            "url": url,
            "extraction_result": {
                "success": result.success,
                "date": result.date,
                "confidence": result.confidence,
                "method": result.method,
                "error_message": result.error_message
            }
        }

    except Exception as e:
        print(f"âŒ æ—¥æœŸæå–æµ‹è¯•å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}


# ä¿®æ”¹ç°æœ‰çš„AIå¤„ç†å‡½æ•°ï¼Œæ”¯æŒæ—¥æœŸæå–
async def ai_process_single_intelligence_with_date_extraction(
        intelligence_id: int,
        db: AsyncSession,
        date_selectors: List[str] = None
):
    """å•ä¸ªæƒ…æŠ¥AIå¤„ç† - é¿å…sessionå†²çªç‰ˆ"""
    try:
        print(f"ğŸ¤– å¼€å§‹AIåˆ†ææƒ…æŠ¥ ID: {intelligence_id}")

        # ä½¿ç”¨åŸç”ŸSQLè·å–æƒ…æŠ¥å’Œæ¥æºï¼Œæé«˜æ€§èƒ½
        from sqlalchemy import text
        result = await db.execute(
            text("""
                SELECT i.id, i.title, i.summary, i.topic, i.news_time, i.content,
                       s.url, s.title as source_title, s.domain
                FROM intelligence i
                LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
                WHERE i.id = :id
                LIMIT 1
            """),
            {"id": intelligence_id}
        )

        row = result.fetchone()
        if not row:
            return {"status": "error", "message": "æƒ…æŠ¥ä¸å­˜åœ¨"}

        # æ„å»ºNewsArticleå¯¹è±¡
        from services.ai_service import analyze_article_with_deepseek, NewsArticle

        def safe_format_datetime(dt_value):
            if dt_value is None:
                return ""
            try:
                if isinstance(dt_value, str):
                    return dt_value
                elif hasattr(dt_value, 'isoformat'):
                    return dt_value.isoformat()
                else:
                    return str(dt_value)
            except Exception:
                return str(dt_value) if dt_value else ""

        article = NewsArticle(
            source=row.domain or "unknown",
            title=row.title,
            url=row.url or "",
            publish_date=safe_format_datetime(row.news_time),
            content=row.content or row.summary or row.title,
            content_hash=""
        )

        print(f"ğŸ“„ å‡†å¤‡åˆ†ææ–‡ç« : {article.title[:50]}...")

        # å…³é”®ä¿®å¤ï¼šåœ¨AIåˆ†æå‰æäº¤å½“å‰äº‹åŠ¡ï¼Œé¿å…å†²çª
        await db.commit()

        # è°ƒç”¨AIåˆ†æï¼Œå¢åŠ è¶…æ—¶æ§åˆ¶
        analysis = await asyncio.wait_for(
            analyze_article_with_deepseek(article, date_selectors=date_selectors),
            timeout=45  # å¢åŠ åˆ°45ç§’è¶…æ—¶
        )

        print(f"ğŸ¯ AIåˆ†æå®Œæˆ")

        # è®¡ç®—ç»¼åˆè¯„åˆ† - ä½¿ç”¨æ–°çš„æƒé‡ç³»ç»Ÿ
        scores = analysis.get("è¯„åˆ†è¯¦æƒ…", {})
        weights = {
            "æˆ˜ç•¥ç›¸å…³æ€§": 0.30,
            "è¡Œä¸šå½±å“åŠ›": 0.20,
            "æ—¶æ•ˆæ€§ç´§è¿«æ€§": 0.20,
            "ä¸šåŠ¡æœºä¼šé£é™©å¼ºåº¦": 0.15,
            "å¯æ“ä½œæ€§": 0.15
        }

        total_score = 0
        for dimension, weight in weights.items():
            score_data = scores.get(dimension, {})
            if isinstance(score_data, dict) and "åˆ†æ•°" in score_data:
                total_score += score_data["åˆ†æ•°"] * weight

        # å‡†å¤‡æ›´æ–°çš„å­—æ®µ
        update_data = {
            "id": intelligence_id,
            "topic": analysis.get("è®®é¢˜", "æœªåˆ†ç±»"),
            "summary": analysis.get("æ‘˜è¦", row.title),
            "ai_score": round(total_score, 1),
            "score_dimensions": json.dumps(scores, ensure_ascii=False),
            "update_time": datetime.now().isoformat()
        }

        # å…³é”®æ–°åŠŸèƒ½ï¼šæ›´æ–°æ ‡é¢˜
        new_title = analysis.get("æ–°æ ‡é¢˜")
        if new_title and new_title.strip() and new_title != row.title:
            update_data["title"] = new_title.strip()
            print(f"ğŸ“ æ ‡é¢˜å°†æ›´æ–°: {row.title[:30]}... â†’ {new_title[:30]}...")

        # æ£€æŸ¥æ˜¯å¦æå–åˆ°äº†æ–°çš„æ—¥æœŸ
        meta_info = analysis.get("_meta", {})
        if meta_info.get("date_extracted") and meta_info.get("extracted_date"):
            update_data["news_time"] = meta_info["extracted_date"]
            print(f"ğŸ“… åŒæ—¶æ›´æ–°æå–åˆ°çš„æ—¥æœŸ: {meta_info['extracted_date']}")

        # æ›´æ–°æ•°æ®åº“ - ä½¿ç”¨æ–°çš„session
        import json

        # æ„å»ºåŠ¨æ€SQLæ›´æ–°è¯­å¥
        set_clauses = []
        for key in update_data.keys():
            if key != "id":
                set_clauses.append(f"{key} = :{key}")

        update_sql = f"""
            UPDATE intelligence 
            SET {', '.join(set_clauses)}
            WHERE id = :id
        """

        await db.execute(text(update_sql), update_data)
        await db.commit()

        result_data = {
            "status": "success",
            "ai_score": round(total_score, 1),
            "dimensions": scores,
            "topic": analysis.get("è®®é¢˜"),
            "summary": analysis.get("æ‘˜è¦"),
            "category": analysis.get("ç±»åˆ«")
        }

        # å¦‚æœæ›´æ–°äº†æ ‡é¢˜ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if "title" in update_data:
            result_data["new_title"] = update_data["title"]
            result_data["original_title"] = row.title

        # å¦‚æœæå–åˆ°äº†æ—¥æœŸï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if meta_info.get("date_extracted"):
            result_data["extracted_date"] = meta_info["extracted_date"]
            result_data["date_extraction_method"] = meta_info.get("date_extraction_method")
            result_data["date_confidence"] = meta_info.get("date_confidence")

        return result_data

    except asyncio.TimeoutError:
        print(f"â° AIåˆ†æè¶…æ—¶: æƒ…æŠ¥ {intelligence_id}")
        return {"status": "error", "message": "AIåˆ†æè¶…æ—¶"}
    except Exception as e:
        print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        await db.rollback()  # å›æ»šäº‹åŠ¡
        return {"status": "error", "message": f"AIåˆ†æå¤±è´¥: {str(e)}"}


# ä¿®æ”¹æ‰¹é‡AIå¤„ç†ï¼Œæ”¯æŒæ—¥æœŸæå–
@api_router.post("/batch-ai-process-with-dates")
async def batch_ai_process_with_date_extraction(
        db: AsyncSession = Depends(get_db),
        request_data: dict = Body(...)
):
    """æ‰¹é‡AIå¤„ç† - å®Œå…¨éš”ç¦»sessionç‰ˆæœ¬"""
    try:
        intelligence_ids = request_data.get("intelligence_ids", [])
        date_selectors = request_data.get("date_selectors", [])

        if not intelligence_ids:
            return {"status": "error", "message": "è¯·æä¾›è¦å¤„ç†çš„æƒ…æŠ¥IDåˆ—è¡¨"}

        print(f"ğŸš€ å¼€å§‹æ‰¹é‡AIåˆ†æ(å«æ—¥æœŸæå–): {len(intelligence_ids)} æ¡æƒ…æŠ¥")

        # å…³é”®ä¿®å¤ï¼šç¡®ä¿å®Œå…¨ä¸²è¡Œï¼Œæ¯ä¸ªä»»åŠ¡ç‹¬ç«‹session
        results = []
        success_count = 0
        start_time = time.time()

        for idx, intel_id in enumerate(intelligence_ids, 1):
            try:
                print(f"ğŸ¤– å¤„ç†æƒ…æŠ¥ {intel_id} ({idx}/{len(intelligence_ids)})...")

                # å…³é”®ä¿®å¤ï¼šæ¯ä¸ªä»»åŠ¡å®Œå…¨ç‹¬ç«‹çš„session
                result = await process_single_intelligence_isolated(intel_id, date_selectors)
                results.append({"id": intel_id, **result})

                if result["status"] == "success":
                    success_count += 1
                    date_info = ""
                    if result.get("extracted_date"):
                        date_info = f"ï¼Œæ—¥æœŸ: {result['extracted_date']}"
                    print(f"âœ… æƒ…æŠ¥ {intel_id} åˆ†ææˆåŠŸï¼Œè¯„åˆ†: {result.get('ai_score', 'N/A')}{date_info}")
                else:
                    print(f"âš ï¸ æƒ…æŠ¥ {intel_id} åˆ†æå¤±è´¥: {result['message']}")

                # å¢åŠ å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«è¯·æ±‚
                if idx < len(intelligence_ids):
                    await asyncio.sleep(0.5)  # å¢åŠ åˆ°0.5ç§’

            except Exception as e:
                print(f"âŒ æƒ…æŠ¥ {intel_id} å¤„ç†å¼‚å¸¸: {e}")
                results.append({
                    "id": intel_id,
                    "status": "error",
                    "message": f"å¤„ç†å¼‚å¸¸: {str(e)}"
                })

        total_time = time.time() - start_time
        date_extracted_count = sum(1 for r in results if r.get('extracted_date'))

        print(
            f"ğŸ‰ æ‰¹é‡AIåˆ†æå®Œæˆ: æˆåŠŸ {success_count}/{len(intelligence_ids)} æ¡ï¼Œæ—¥æœŸæå– {date_extracted_count} æ¡ï¼Œè€—æ—¶ {total_time:.2f}ç§’")

        return {
            "status": "success",
            "message": f"æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {len(intelligence_ids) - success_count} æ¡ï¼Œæ—¥æœŸæå– {date_extracted_count} æ¡",
            "results": results,
            "success_count": success_count,
            "total_count": len(intelligence_ids),
            "date_extracted_count": date_extracted_count,
            "processing_time": round(total_time, 2),
            "average_time": round(total_time / len(intelligence_ids), 2)
        }

    except Exception as e:
        print(f"âŒ æ‰¹é‡AIå¤„ç†å¤±è´¥: {e}")
        return {"status": "error", "message": f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}"}


# æ–°å¢ï¼šå®Œå…¨éš”ç¦»çš„å•ä¸ªå¤„ç†å‡½æ•°
async def process_single_intelligence_isolated(intelligence_id: int, date_selectors: List[str] = None):
    """å®Œå…¨éš”ç¦»çš„å•ä¸ªæƒ…æŠ¥å¤„ç† - é¿å…å¹¶å‘å†²çª"""
    ai_db = None
    try:
        # åˆ›å»ºç‹¬ç«‹çš„session
        ai_db = await get_ai_processing_db()

        # è°ƒç”¨å¤„ç†å‡½æ•°
        result = await ai_process_single_intelligence_with_date_extraction(
            intelligence_id, ai_db, date_selectors
        )

        return result

    except Exception as e:
        print(f"âŒ éš”ç¦»å¤„ç†å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}

    finally:
        # ç¡®ä¿sessionè¢«æ­£ç¡®å…³é—­
        if ai_db:
            try:
                await ai_db.close()
            except Exception as close_error:
                print(f"âš ï¸ å…³é—­sessionæ—¶å‡ºé”™: {close_error}")


# ä¿®æ”¹ç°æœ‰çš„çˆ¬è™«å‡½æ•°ï¼Œåœ¨çˆ¬è™«é˜¶æ®µå°±å°è¯•æå–æ—¥æœŸ
@api_router.post("/crawl-with-date-extraction")
async def start_crawling_with_date_extraction(
        db: AsyncSession = Depends(get_db),
        topic_ids: str = Form(..., description="é€‰æ‹©çš„è®®é¢˜IDï¼Œé€—å·åˆ†éš”"),
        days_back: int = Form(7, description="çˆ¬å–å‡ å¤©å†…çš„æ–°é—»"),
        max_items_per_source: int = Form(20, description="æ¯ä¸ªæºæœ€å¤§çˆ¬å–æ•°é‡"),
        enable_date_extraction: bool = Form(True, description="æ˜¯å¦å¯ç”¨æ—¥æœŸæå–")
):
    """æ™ºèƒ½çˆ¬å–åŠŸèƒ½ - æ”¯æŒåœ¨çˆ¬å–é˜¶æ®µæå–æ—¥æœŸ"""
    try:
        print("\n" + "=" * 60)
        print(f"ğŸš€ å¼€å§‹æ™ºèƒ½çˆ¬å–ä»»åŠ¡(å«æ—¥æœŸæå–)")
        print(
            f"ğŸ“‹ å‚æ•°: topic_ids={topic_ids}, days_back={days_back}, max_items={max_items_per_source}, date_extraction={enable_date_extraction}")
        print("=" * 60 + "\n")

        # è§£æè®®é¢˜IDåˆ—è¡¨
        topic_id_list = [int(id.strip()) for id in topic_ids.split(',') if id.strip()]

        if not topic_id_list:
            return {"status": "error", "message": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè®®é¢˜"}

        # æŸ¥è¯¢è®®é¢˜å’Œæºï¼Œè·å–æ—¥æœŸé€‰æ‹©å™¨é…ç½®
        from sqlalchemy import select
        from models.base_models import Topic, Source, topic_source_association

        # è·å–è®®é¢˜
        topics_result = await db.execute(
            select(Topic).where(Topic.id.in_(topic_id_list))
        )
        topics = topics_result.scalars().all()

        if not topics:
            return {"status": "error", "message": "æœªæ‰¾åˆ°é€‰æ‹©çš„è®®é¢˜"}

        print(f"âœ… æ‰¾åˆ° {len(topics)} ä¸ªè®®é¢˜")

        # è®¡ç®—æ—¶é—´èŒƒå›´
        from datetime import datetime, timedelta
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")

        crawl_results = []
        total_crawled = 0
        total_saved = 0
        total_date_extracted = 0  # æ–°å¢ï¼šç»Ÿè®¡æ—¥æœŸæå–æˆåŠŸæ•°

        # å¤„ç†æ¯ä¸ªè®®é¢˜
        for topic_idx, topic in enumerate(topics, 1):
            # æå‰ä¿å­˜topicå±æ€§ï¼Œé¿å…åç»­æ‡’åŠ è½½
            topic_id = topic.id
            topic_name = topic.name

            print(f"\n{'=' * 50}")
            print(f"ğŸ¯ å¤„ç†è®®é¢˜ [{topic_idx}/{len(topics)}]: {topic_name}")

            # è·å–è¯¥è®®é¢˜çš„æ‰€æœ‰æºåŠå…¶é…ç½®
            sources_result = await db.execute(
                select(Source)
                .join(topic_source_association)
                .where(topic_source_association.c.topic_id == topic_id)
            )
            topic_sources = sources_result.scalars().all()

            print(f"   è¯¥è®®é¢˜ä¸‹æœ‰ {len(topic_sources)} ä¸ªä¿¡æ¯æº")
            print(f"{'=' * 50}")

            topic_results = {
                "topic_id": topic_id,
                "topic_name": topic_name,
                "sources": [],
                "total_items": 0,
                "total_saved": 0,
                "total_date_extracted": 0  # æ–°å¢
            }

            # å¤„ç†æ¯ä¸ªä¿¡æ¯æº
            for source_idx, source in enumerate(topic_sources, 1):
                # é‡è¦ï¼šæå‰è¯»å–æ‰€æœ‰éœ€è¦çš„å±æ€§
                source_domain = source.domain
                source_recipe_json = source.recipe_json

                print(f"\n   [{source_idx}/{len(topic_sources)}] çˆ¬å–ä¿¡æ¯æº: {source_domain}")
                print(f"   " + "-" * 40)

                try:
                    # è§£æé…æ–¹ï¼Œæå–æ—¥æœŸé€‰æ‹©å™¨
                    import json
                    if isinstance(source_recipe_json, str):
                        recipe_data = json.loads(source_recipe_json)
                    else:
                        recipe_data = source_recipe_json

                    # è·å–æ—¥æœŸé€‰æ‹©å™¨é…ç½®
                    date_selectors = []
                    if enable_date_extraction and recipe_data:
                        date_selector = recipe_data.get('date_selector')
                        if date_selector:
                            # å¤„ç†å¤šä¸ªé€‰æ‹©å™¨ï¼ˆé€—å·åˆ†éš”ï¼‰
                            date_selectors = [s.strip() for s in date_selector.split(',') if s.strip()]
                            print(f"   ğŸ“… æ—¥æœŸé€‰æ‹©å™¨: {date_selectors}")

                    # åˆ›å»ºçˆ¬è™«
                    from scraper.models import ScraperRecipe
                    from scraper.scraper_main import Scraper

                    recipe = ScraperRecipe(**recipe_data)
                    scraper = Scraper(recipe)

                    # æ‰§è¡Œçˆ¬å–
                    print(f"   â³ æ­£åœ¨çˆ¬å–ï¼Œæœ€å¤šè·å– {max_items_per_source} æ¡...")
                    start_time = datetime.now()

                    items, meta = await scraper.scrape(max_links=max_items_per_source)

                    elapsed = (datetime.now() - start_time).total_seconds()
                    print(f"   âœ… çˆ¬å–å®Œæˆï¼Œè€—æ—¶ {elapsed:.1f} ç§’")
                    print(f"   ğŸ“Š è·å–åˆ° {len(items)} æ¡æ•°æ®")

                    saved_count = 0
                    updated_count = 0
                    duplicate_count = 0
                    out_of_range_count = 0
                    date_extracted_count = 0  # æ–°å¢ï¼šå½“å‰æºçš„æ—¥æœŸæå–ç»Ÿè®¡

                    for item_idx, item in enumerate(items, 1):
                        try:
                            # å®‰å…¨çš„æ—¶é—´å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            news_time = None
                            if hasattr(item, 'date') and item.date:
                                try:
                                    if isinstance(item.date, str) and item.date.strip():
                                        from dateutil import parser
                                        # æ·»åŠ æ¨¡ç³Šè§£ææ”¯æŒ
                                        try:
                                            news_time = parser.parse(item.date.strip())
                                        except:
                                            news_time = parser.parse(item.date.strip(), fuzzy=True)
                                    elif isinstance(item.date, datetime):
                                        news_time = item.date
                                except Exception as e:
                                    print(f"      ğŸ“… æ—¥æœŸè§£æå¤±è´¥: {item.date}, é”™è¯¯: {e}")
                                    news_time = None

                            # å¦‚æœåˆ—è¡¨é¡µæ²¡æœ‰æ—¥æœŸï¼Œä½†å¯ç”¨äº†æ—¥æœŸæå–ï¼Œå°è¯•ä»å…·ä½“é“¾æ¥è·å–
                            if news_time is None and enable_date_extraction and date_selectors and item.url:
                                try:
                                    print(f"      ğŸ” å°è¯•ä»é“¾æ¥æå–æ—¥æœŸ: {item.url[:50]}...")

                                    from services.ai_service import extract_date_from_url
                                    date_result = await extract_date_from_url(item.url, date_selectors)

                                    if date_result.success:
                                        from dateutil import parser
                                        news_time = parser.parse(date_result.date)
                                        date_extracted_count += 1
                                        print(f"      âœ… æˆåŠŸæå–æ—¥æœŸ: {date_result.date} (æ–¹æ³•: {date_result.method})")
                                    else:
                                        print(f"      âš ï¸ æ—¥æœŸæå–å¤±è´¥: {date_result.error_message}")

                                except Exception as e:
                                    print(f"      âŒ æ—¥æœŸæå–å‡ºé”™: {e}")

                            # æ—¶é—´èŒƒå›´æ£€æŸ¥ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            if news_time is not None:
                                if news_time < start_date - timedelta(days=7):
                                    out_of_range_count += 1
                                    continue

                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ ‡é¢˜çš„è®°å½•
                            existing_result = await db.execute(
                                text("SELECT id, news_time FROM intelligence WHERE title = :title LIMIT 1"),
                                {"title": item.title}
                            )
                            existing_row = existing_result.fetchone()

                            current_time = datetime.now()

                            if existing_row:
                                existing_id, existing_news_time = existing_row

                                # å¦‚æœç°æœ‰è®°å½•æ²¡æœ‰æ—¥æœŸï¼Œä½†æ–°æ•°æ®æœ‰æ—¥æœŸï¼Œåˆ™æ›´æ–°
                                if existing_news_time is None and news_time is not None:
                                    await db.execute(
                                        text("""
                                            UPDATE intelligence 
                                            SET news_time = :news_time, 
                                                update_time = :update_time,
                                                topic = :topic
                                            WHERE id = :id
                                        """),
                                        {
                                            "id": existing_id,
                                            "news_time": news_time.isoformat(),
                                            "update_time": current_time.isoformat(),
                                            "topic": topic_name
                                        }
                                    )

                                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æˆ–æ·»åŠ æ¥æº
                                    source_check = await db.execute(
                                        text(
                                            "SELECT COUNT(*) FROM intelligence_sources WHERE intelligence_id = :id AND url = :url"),
                                        {"id": existing_id, "url": item.url}
                                    )

                                    if source_check.scalar() == 0:
                                        await db.execute(
                                            text("""
                                                INSERT INTO intelligence_sources (
                                                    intelligence_id, url, title, domain, fetch_time
                                                ) VALUES (
                                                    :intelligence_id, :url, :title, :domain, :fetch_time
                                                )
                                            """),
                                            {
                                                'intelligence_id': existing_id,
                                                'url': item.url,
                                                'title': item.title,
                                                'domain': source_domain,
                                                'fetch_time': current_time.isoformat()
                                            }
                                        )

                                    updated_count += 1
                                    print(f"      âœ… æ›´æ–°è®°å½•æ—¥æœŸ: {item.title[:40]}...")
                                else:
                                    duplicate_count += 1
                                    if item_idx % 50 == 0:  # å‡å°‘é‡å¤æ—¥å¿—
                                        print(f"      âš ï¸ å·²å¤„ç† {duplicate_count} ä¸ªé‡å¤è®°å½•...")
                                continue

                            # æ’å…¥æ–°è®°å½•ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            news_time_str = news_time.isoformat() if news_time else None

                            insert_result = await db.execute(
                                text("""
                                    INSERT INTO intelligence (
                                        title, summary, topic, news_time, collect_time, update_time,
                                        quality_status, ai_score, score_dimensions, is_merged, merged_count
                                    ) VALUES (
                                        :title, :summary, :topic, :news_time, :collect_time, :update_time,
                                        :quality_status, :ai_score, :score_dimensions, :is_merged, :merged_count
                                    )
                                """),
                                {
                                    'title': item.title,
                                    'summary': '',
                                    'topic': topic_name,
                                    'news_time': news_time_str,
                                    'collect_time': current_time.isoformat(),
                                    'update_time': current_time.isoformat(),
                                    'quality_status': 'pending',
                                    'ai_score': 0.0,
                                    'score_dimensions': '{}',
                                    'is_merged': 0,
                                    'merged_count': 0
                                }
                            )

                            # æ’å…¥æ¥æºè®°å½•ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            intelligence_id = insert_result.lastrowid
                            await db.execute(
                                text("""
                                    INSERT INTO intelligence_sources (
                                        intelligence_id, url, title, domain, fetch_time
                                    ) VALUES (
                                        :intelligence_id, :url, :title, :domain, :fetch_time
                                    )
                                """),
                                {
                                    'intelligence_id': intelligence_id,
                                    'url': item.url,
                                    'title': item.title,
                                    'domain': source_domain,
                                    'fetch_time': current_time.isoformat()
                                }
                            )

                            saved_count += 1
                            if saved_count % 10 == 0:
                                print(f"      ğŸ’¾ å·²ä¿å­˜ {saved_count} æ¡æ–°è®°å½•...")

                        except Exception as e:
                            print(f"      âŒ ä¿å­˜å¤±è´¥ [{item_idx}]: {str(e)[:50]}")
                            continue

                    # æäº¤æ•°æ®åº“
                    if saved_count > 0 or updated_count > 0:
                        await db.commit()
                        print(f"   âœ… æˆåŠŸä¿å­˜ {saved_count} æ¡æ–°è®°å½•ï¼Œæ›´æ–° {updated_count} æ¡è®°å½•")

                    print(
                        f"   ğŸ“Š ç»Ÿè®¡: æ–°å¢={saved_count}, æ›´æ–°={updated_count}, é‡å¤={duplicate_count}, è¶…æ—¶={out_of_range_count}, æ—¥æœŸæå–={date_extracted_count}")

                    # æ„å»ºç»“æœï¼ˆä½¿ç”¨ä¿å­˜çš„å˜é‡ï¼‰
                    source_result = {
                        "domain": source_domain,
                        "status": "success",
                        "crawled": len(items),
                        "saved": saved_count,
                        "duplicate": duplicate_count,
                        "out_of_range": out_of_range_count,
                        "date_extracted": date_extracted_count,  # æ–°å¢
                        "meta": meta
                    }

                    topic_results["sources"].append(source_result)
                    topic_results["total_items"] += len(items)
                    topic_results["total_saved"] += saved_count
                    topic_results["total_date_extracted"] += date_extracted_count  # æ–°å¢

                    total_crawled += len(items)
                    total_saved += saved_count
                    total_date_extracted += date_extracted_count  # æ–°å¢

                except Exception as e:
                    print(f"   âŒ çˆ¬å–å¤±è´¥: {e}")

                    # é”™è¯¯å¤„ç†ï¼ˆä½¿ç”¨ä¿å­˜çš„å˜é‡ï¼‰
                    topic_results["sources"].append({
                        "domain": source_domain,
                        "status": "error",
                        "message": str(e)[:200]
                    })

            crawl_results.append(topic_results)
            print(
                f"\nâœ… è®®é¢˜ '{topic_name}' å¤„ç†å®Œæˆ: çˆ¬å–={topic_results['total_items']}, ä¿å­˜={topic_results['total_saved']}, æ—¥æœŸæå–={topic_results['total_date_extracted']}")

        # å®Œæˆæ€»ç»“
        print("\n" + "=" * 60)
        print(f"ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆ!")
        print(f"ğŸ“Š æ€»è®¡: çˆ¬å–={total_crawled} æ¡, ä¿å­˜={total_saved} æ¡, æ—¥æœŸæå–={total_date_extracted} æ¡")
        print("=" * 60 + "\n")

        return {
            "status": "success",
            "message": f"æˆåŠŸçˆ¬å– {total_crawled} æ¡ï¼Œä¿å­˜ {total_saved} æ¡æƒ…æŠ¥ï¼Œæ—¥æœŸæå– {total_date_extracted} æ¡",
            "total_crawled": total_crawled,
            "total_saved": total_saved,
            "total_date_extracted": total_date_extracted,  # æ–°å¢
            "time_range": {
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat(),
                "days": days_back
            },
            "results": crawl_results
        }

    except Exception as e:
        print(f"\nâŒ çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        await db.rollback()  # æ·»åŠ å›æ»š
        return {"status": "error", "message": f"çˆ¬å–å¤±è´¥: {str(e)}"}


@api_router.get("/topics")
async def get_all_topics(db: AsyncSession = Depends(get_db)):
    """è·å–æ‰€æœ‰å¯ç”¨çš„è®®é¢˜åˆ—è¡¨"""
    try:
        result = await db.execute(
            select(Topic).options(selectinload(Topic.sources)).order_by(Topic.name)
        )
        topics = result.scalars().all()

        return {
            "status": "success",
            "topics": [
                {
                    "id": topic.id,
                    "name": topic.name,
                    "description": topic.description or "",
                    "source_count": len(topic.sources) if topic.sources else 0,
                    "domains": [source.domain for source in topic.sources] if topic.sources else []
                }
                for topic in topics
            ]
        }
    except Exception as e:
        print(f"è·å–è®®é¢˜å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}


@api_router.post("/crawl")
async def start_crawling(
        db: AsyncSession = Depends(get_db),
        topic_ids: str = Form(..., description="é€‰æ‹©çš„è®®é¢˜IDï¼Œé€—å·åˆ†éš”"),
        days_back: int = Form(7, description="çˆ¬å–å‡ å¤©å†…çš„æ–°é—»"),
        max_items_per_source: int = Form(20, description="æ¯ä¸ªæºæœ€å¤§çˆ¬å–æ•°é‡")
):
    """æ™ºèƒ½çˆ¬å–åŠŸèƒ½ - å®Œæ•´ä¿®å¤ç‰ˆ"""
    try:
        print("\n" + "=" * 60)
        print(f"ğŸš€ å¼€å§‹æ™ºèƒ½çˆ¬å–ä»»åŠ¡")
        print(f"ğŸ“ å‚æ•°: topic_ids={topic_ids}, days_back={days_back}, max_items={max_items_per_source}")
        print("=" * 60 + "\n")

        # è§£æè®®é¢˜IDåˆ—è¡¨
        topic_id_list = [int(id.strip()) for id in topic_ids.split(',') if id.strip()]

        if not topic_id_list:
            return {"status": "error", "message": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè®®é¢˜"}

        # æŸ¥è¯¢è®®é¢˜å’Œæº
        from sqlalchemy import select
        from models.base_models import Topic, Source, topic_source_association

        # è·å–è®®é¢˜
        topics_result = await db.execute(
            select(Topic).where(Topic.id.in_(topic_id_list))
        )
        topics = topics_result.scalars().all()

        if not topics:
            return {"status": "error", "message": "æœªæ‰¾åˆ°é€‰æ‹©çš„è®®é¢˜"}

        print(f"âœ… æ‰¾åˆ° {len(topics)} ä¸ªè®®é¢˜")

        # è®¡ç®—æ—¶é—´èŒƒå›´
        from datetime import datetime, timedelta
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")

        crawl_results = []
        total_crawled = 0
        total_saved = 0

        # å¤„ç†æ¯ä¸ªè®®é¢˜
        for topic_idx, topic in enumerate(topics, 1):
            # æå‰ä¿å­˜topicå±æ€§ï¼Œé¿å…åç»­æ‡’åŠ è½½
            topic_id = topic.id
            topic_name = topic.name

            print(f"\n{'=' * 50}")
            print(f"ğŸ¯ å¤„ç†è®®é¢˜ [{topic_idx}/{len(topics)}]: {topic_name}")

            # è·å–è¯¥è®®é¢˜çš„æ‰€æœ‰æº
            sources_result = await db.execute(
                select(Source)
                .join(topic_source_association)
                .where(topic_source_association.c.topic_id == topic_id)
            )
            topic_sources = sources_result.scalars().all()

            print(f"   è¯¥è®®é¢˜ä¸‹æœ‰ {len(topic_sources)} ä¸ªä¿¡æ¯æº")
            print(f"{'=' * 50}")

            topic_results = {
                "topic_id": topic_id,
                "topic_name": topic_name,
                "sources": [],
                "total_items": 0,
                "total_saved": 0
            }

            # å¤„ç†æ¯ä¸ªä¿¡æ¯æº
            for source_idx, source in enumerate(topic_sources, 1):
                # é‡è¦ï¼šæå‰è¯»å–æ‰€æœ‰éœ€è¦çš„å±æ€§
                source_domain = source.domain
                source_recipe_json = source.recipe_json

                print(f"\n   [{source_idx}/{len(topic_sources)}] çˆ¬å–ä¿¡æ¯æº: {source_domain}")
                print(f"   " + "-" * 40)

                try:
                    # è§£æé…æ–¹
                    import json
                    if isinstance(source_recipe_json, str):
                        recipe_data = json.loads(source_recipe_json)
                    else:
                        recipe_data = source_recipe_json

                    # åˆ›å»ºçˆ¬è™«
                    from scraper.models import ScraperRecipe
                    from scraper.scraper_main import Scraper

                    recipe = ScraperRecipe(**recipe_data)
                    scraper = Scraper(recipe)

                    # æ‰§è¡Œçˆ¬å–
                    print(f"   â³ æ­£åœ¨çˆ¬å–ï¼Œæœ€å¤šè·å– {max_items_per_source} æ¡...")
                    start_time = datetime.now()

                    items, meta = await scraper.scrape(max_links=max_items_per_source)

                    elapsed = (datetime.now() - start_time).total_seconds()
                    print(f"   âœ… çˆ¬å–å®Œæˆï¼Œè€—æ—¶ {elapsed:.1f} ç§’")
                    print(f"   ğŸ“Š è·å–åˆ° {len(items)} æ¡æ•°æ®")

                    saved_count = 0
                    updated_count = 0
                    duplicate_count = 0
                    out_of_range_count = 0

                    for item_idx, item in enumerate(items, 1):
                        try:
                            # å®‰å…¨çš„æ—¶é—´å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            news_time = None
                            if hasattr(item, 'date') and item.date:
                                try:
                                    if isinstance(item.date, str) and item.date.strip():
                                        from dateutil import parser
                                        # æ·»åŠ æ¨¡ç³Šè§£ææ”¯æŒ
                                        try:
                                            news_time = parser.parse(item.date.strip())
                                        except:
                                            news_time = parser.parse(item.date.strip(), fuzzy=True)
                                    elif isinstance(item.date, datetime):
                                        news_time = item.date
                                except Exception as e:
                                    print(f"      ğŸ“… æ—¥æœŸè§£æå¤±è´¥: {item.date}, é”™è¯¯: {e}")
                                    news_time = None

                            # æ—¶é—´èŒƒå›´æ£€æŸ¥ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            if news_time is not None:
                                if news_time < start_date - timedelta(days=7):
                                    out_of_range_count += 1
                                    continue

                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ ‡é¢˜çš„è®°å½•
                            existing_result = await db.execute(
                                text("SELECT id, news_time FROM intelligence WHERE title = :title LIMIT 1"),
                                {"title": item.title}
                            )
                            existing_row = existing_result.fetchone()

                            current_time = datetime.now()

                            if existing_row:
                                existing_id, existing_news_time = existing_row

                                # å¦‚æœç°æœ‰è®°å½•æ²¡æœ‰æ—¥æœŸï¼Œä½†æ–°æ•°æ®æœ‰æ—¥æœŸï¼Œåˆ™æ›´æ–°
                                if existing_news_time is None and news_time is not None:
                                    await db.execute(
                                        text("""
                                            UPDATE intelligence 
                                            SET news_time = :news_time, 
                                                update_time = :update_time,
                                                topic = :topic
                                            WHERE id = :id
                                        """),
                                        {
                                            "id": existing_id,
                                            "news_time": news_time.isoformat(),
                                            "update_time": current_time.isoformat(),
                                            "topic": topic_name
                                        }
                                    )

                                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æˆ–æ·»åŠ æ¥æº
                                    source_check = await db.execute(
                                        text(
                                            "SELECT COUNT(*) FROM intelligence_sources WHERE intelligence_id = :id AND url = :url"),
                                        {"id": existing_id, "url": item.url}
                                    )

                                    if source_check.scalar() == 0:
                                        await db.execute(
                                            text("""
                                                INSERT INTO intelligence_sources (
                                                    intelligence_id, url, title, domain, fetch_time
                                                ) VALUES (
                                                    :intelligence_id, :url, :title, :domain, :fetch_time
                                                )
                                            """),
                                            {
                                                'intelligence_id': existing_id,
                                                'url': item.url,
                                                'title': item.title,
                                                'domain': source_domain,
                                                'fetch_time': current_time.isoformat()
                                            }
                                        )

                                    updated_count += 1
                                    print(f"      âœ… æ›´æ–°è®°å½•æ—¥æœŸ: {item.title[:40]}...")
                                else:
                                    duplicate_count += 1
                                    if item_idx % 50 == 0:  # å‡å°‘é‡å¤æ—¥å¿—
                                        print(f"      âš ï¸ å·²å¤„ç† {duplicate_count} ä¸ªé‡å¤è®°å½•...")
                                continue

                            # æ’å…¥æ–°è®°å½•ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            news_time_str = news_time.isoformat() if news_time else None

                            insert_result = await db.execute(
                                text("""
                                    INSERT INTO intelligence (
                                        title, summary, topic, news_time, collect_time, update_time,
                                        quality_status, ai_score, score_dimensions, is_merged, merged_count
                                    ) VALUES (
                                        :title, :summary, :topic, :news_time, :collect_time, :update_time,
                                        :quality_status, :ai_score, :score_dimensions, :is_merged, :merged_count
                                    )
                                """),
                                {
                                    'title': item.title,
                                    'summary': '',
                                    'topic': topic_name,
                                    'news_time': news_time_str,
                                    'collect_time': current_time.isoformat(),
                                    'update_time': current_time.isoformat(),
                                    'quality_status': 'pending',
                                    'ai_score': 0.0,
                                    'score_dimensions': '{}',
                                    'is_merged': 0,
                                    'merged_count': 0
                                }
                            )

                            # æ’å…¥æ¥æºè®°å½•ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                            intelligence_id = insert_result.lastrowid
                            await db.execute(
                                text("""
                                    INSERT INTO intelligence_sources (
                                        intelligence_id, url, title, domain, fetch_time
                                    ) VALUES (
                                        :intelligence_id, :url, :title, :domain, :fetch_time
                                    )
                                """),
                                {
                                    'intelligence_id': intelligence_id,
                                    'url': item.url,
                                    'title': item.title,
                                    'domain': source_domain,
                                    'fetch_time': current_time.isoformat()
                                }
                            )

                            saved_count += 1
                            if saved_count % 10 == 0:
                                print(f"      ğŸ’¾ å·²ä¿å­˜ {saved_count} æ¡æ–°è®°å½•...")

                        except Exception as e:
                            print(f"      âŒ ä¿å­˜å¤±è´¥ [{item_idx}]: {str(e)[:50]}")
                            continue

                    # æäº¤æ•°æ®åº“
                    if saved_count > 0 or updated_count > 0:
                        await db.commit()
                        print(f"   âœ… æˆåŠŸä¿å­˜ {saved_count} æ¡æ–°è®°å½•ï¼Œæ›´æ–° {updated_count} æ¡è®°å½•")

                    print(
                        f"   ğŸ“Š ç»Ÿè®¡: æ–°å¢={saved_count}, æ›´æ–°={updated_count}, é‡å¤={duplicate_count}, è¶…æ—¶={out_of_range_count}")

                    # æ„å»ºç»“æœï¼ˆä½¿ç”¨ä¿å­˜çš„å˜é‡ï¼‰
                    source_result = {
                        "domain": source_domain,
                        "status": "success",
                        "crawled": len(items),
                        "saved": saved_count,
                        "duplicate": duplicate_count,
                        "out_of_range": out_of_range_count,
                        "meta": meta
                    }

                    topic_results["sources"].append(source_result)
                    topic_results["total_items"] += len(items)
                    topic_results["total_saved"] += saved_count
                    total_crawled += len(items)
                    total_saved += saved_count

                except Exception as e:
                    print(f"   âŒ çˆ¬å–å¤±è´¥: {e}")

                    # é”™è¯¯å¤„ç†ï¼ˆä½¿ç”¨ä¿å­˜çš„å˜é‡ï¼‰
                    topic_results["sources"].append({
                        "domain": source_domain,
                        "status": "error",
                        "message": str(e)[:200]
                    })

            crawl_results.append(topic_results)
            print(
                f"\nâœ… è®®é¢˜ '{topic_name}' å¤„ç†å®Œæˆ: çˆ¬å–={topic_results['total_items']}, ä¿å­˜={topic_results['total_saved']}")

        # å®Œæˆæ€»ç»“
        print("\n" + "=" * 60)
        print(f"ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆ!")
        print(f"ğŸ“Š æ€»è®¡: çˆ¬å–={total_crawled} æ¡, ä¿å­˜={total_saved} æ¡")
        print("=" * 60 + "\n")

        return {
            "status": "success",
            "message": f"æˆåŠŸçˆ¬å– {total_crawled} æ¡ï¼Œä¿å­˜ {total_saved} æ¡æƒ…æŠ¥",
            "total_crawled": total_crawled,
            "total_saved": total_saved,
            "time_range": {
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat(),
                "days": days_back
            },
            "results": crawl_results
        }

    except Exception as e:
        print(f"\nâŒ çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        await db.rollback()  # æ·»åŠ å›æ»š
        return {"status": "error", "message": f"çˆ¬å–å¤±è´¥: {str(e)}"}


@api_router.get("/list", response_model=Dict[str, Any])
async def get_intelligence_list(
        db: AsyncSession = Depends(get_db),
        page: int = Query(1, ge=1),
        page_size: int = Query(20, ge=10, le=100),
        title: Optional[str] = Query(None),
        topic: Optional[str] = Query(None),
        quality: Optional[str] = Query(None),
        min_score: Optional[float] = Query(None),
        max_score: Optional[float] = Query(None),
        # ä¿®æ”¹ï¼šæ·»åŠ æ–°é—»æ—¶é—´ç­›é€‰å‚æ•°
        news_start_date: Optional[str] = Query(None, description="æŒ‰æ–°é—»æ—¶é—´ç­›é€‰çš„å¼€å§‹æ—¥æœŸ"),
        news_end_date: Optional[str] = Query(None, description="æŒ‰æ–°é—»æ—¶é—´ç­›é€‰çš„ç»“æŸæ—¥æœŸ"),
        # ä¿ç•™åŸæœ‰çš„æ”¶é›†æ—¶é—´ç­›é€‰å‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
        start_date: Optional[str] = Query(None, description="æŒ‰æ”¶é›†æ—¶é—´ç­›é€‰çš„å¼€å§‹æ—¥æœŸ"),
        end_date: Optional[str] = Query(None, description="æŒ‰æ”¶é›†æ—¶é—´ç­›é€‰çš„ç»“æŸæ—¥æœŸ"),
        sort_by: str = Query("news_time", description="æ’åºå­—æ®µï¼Œé»˜è®¤æŒ‰æ–°é—»æ—¶é—´"),  # ä¿®æ”¹é»˜è®¤æ’åº
        order: str = Query("desc")
):
    """è·å–æƒ…æŠ¥åˆ—è¡¨ - æ”¯æŒæŒ‰æ–°é—»æ—¶é—´ç­›é€‰å’Œæ’åº"""
    try:
        print(f"ğŸ“‹ æŸ¥è¯¢å‚æ•°: page={page}, page_size={page_size}")
        print(f"ğŸ“… æ–°é—»æ—¶é—´ç­›é€‰: {news_start_date} åˆ° {news_end_date}")

        # é‡è¦ï¼šå°†æ‰€æœ‰å‚æ•°è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œé¿å…Queryå¯¹è±¡é—®é¢˜
        title_str = str(title) if title is not None else None
        topic_str = str(topic) if topic is not None else None
        quality_str = str(quality) if quality is not None else None
        news_start_date_str = str(news_start_date) if news_start_date is not None else None
        news_end_date_str = str(news_end_date) if news_end_date is not None else None
        start_date_str = str(start_date) if start_date is not None else None
        end_date_str = str(end_date) if end_date is not None else None

        print(f"ğŸ“‹ è½¬æ¢åå‚æ•°: title={title_str}, topic={topic_str}, quality={quality_str}")

        # æ„å»ºSQLæŸ¥è¯¢æ¡ä»¶
        where_conditions = []
        params = {}

        # å­—ç¬¦ä¸²æ¡ä»¶ - ä¸¥æ ¼æ£€æŸ¥
        if title_str and title_str.strip() and title_str not in ["None", "null", ""]:
            where_conditions.append("title LIKE :title")
            params['title'] = f"%{title_str.strip()}%"

        if topic_str and topic_str.strip() and topic_str not in ["None", "null", ""]:
            where_conditions.append("topic LIKE :topic")
            params['topic'] = f"%{topic_str.strip()}%"

        if quality_str and quality_str.strip() and quality_str not in ["None", "null", ""]:
            where_conditions.append("quality_status = :quality")
            params['quality'] = quality_str.strip()

        # æ•°å­—æ¡ä»¶
        if min_score is not None and str(min_score) not in ["None", "null", ""]:
            try:
                score_val = float(min_score)
                where_conditions.append("ai_score >= :min_score")
                params['min_score'] = score_val
            except (ValueError, TypeError):
                pass

        if max_score is not None and str(max_score) not in ["None", "null", ""]:
            try:
                score_val = float(max_score)
                where_conditions.append("ai_score <= :max_score")
                params['max_score'] = score_val
            except (ValueError, TypeError):
                pass

        # æ–°é—»æ—¶é—´ç­›é€‰ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
        if news_start_date_str and news_start_date_str not in ["None", "null", ""]:
            try:
                from dateutil import parser
                start_dt = parser.parse(news_start_date_str)
                where_conditions.append("news_time >= :news_start_date")
                params['news_start_date'] = start_dt
                print(f"ğŸ“… æ·»åŠ æ–°é—»å¼€å§‹æ—¶é—´ç­›é€‰: {start_dt}")
            except Exception as e:
                print(f"âš ï¸ æ–°é—»å¼€å§‹æ—¶é—´è§£æå¤±è´¥: {e}")

        if news_end_date_str and news_end_date_str not in ["None", "null", ""]:
            try:
                from dateutil import parser
                end_dt = parser.parse(news_end_date_str)
                where_conditions.append("news_time <= :news_end_date")
                params['news_end_date'] = end_dt
                print(f"ğŸ“… æ·»åŠ æ–°é—»ç»“æŸæ—¶é—´ç­›é€‰: {end_dt}")
            except Exception as e:
                print(f"âš ï¸ æ–°é—»ç»“æŸæ—¶é—´è§£æå¤±è´¥: {e}")

        # æ”¶é›†æ—¶é—´ç­›é€‰ï¼ˆå‘åå…¼å®¹ï¼Œä»…åœ¨æ²¡æœ‰æ–°é—»æ—¶é—´ç­›é€‰æ—¶ä½¿ç”¨ï¼‰
        elif start_date_str and start_date_str not in ["None", "null", ""]:
            try:
                from dateutil import parser
                start_dt = parser.parse(start_date_str)
                where_conditions.append("collect_time >= :start_date")
                params['start_date'] = start_dt
                print(f"ğŸ“… æ·»åŠ æ”¶é›†å¼€å§‹æ—¶é—´ç­›é€‰: {start_dt}")
            except Exception as e:
                print(f"âš ï¸ æ”¶é›†å¼€å§‹æ—¶é—´è§£æå¤±è´¥: {e}")

        elif end_date_str and end_date_str not in ["None", "null", ""]:
            try:
                from dateutil import parser
                end_dt = parser.parse(end_date_str)
                where_conditions.append("collect_time <= :end_date")
                params['end_date'] = end_dt
                print(f"ğŸ“… æ·»åŠ æ”¶é›†ç»“æŸæ—¶é—´ç­›é€‰: {end_dt}")
            except Exception as e:
                print(f"âš ï¸ æ”¶é›†ç»“æŸæ—¶é—´è§£æå¤±è´¥: {e}")

        # æ„å»ºWHEREå­å¥
        where_clause = ""
        if where_conditions:
            where_clause = "WHERE " + " AND ".join(where_conditions)

        print(f"ğŸ“‹ WHEREå­å¥: {where_clause}")
        print(f"ğŸ“‹ SQLå‚æ•°: {params}")

        # æ„å»ºæ’åº - æ”¯æŒæŒ‰æ–°é—»æ—¶é—´æ’åº
        valid_sort_fields = ["id", "title", "topic", "news_time", "collect_time", "ai_score", "quality_status"]
        if sort_by not in valid_sort_fields:
            sort_by = "news_time"  # é»˜è®¤æŒ‰æ–°é—»æ—¶é—´æ’åº

        # ç‰¹æ®Šå¤„ç†æ–°é—»æ—¶é—´æ’åºï¼šNULLå€¼æ’åœ¨æœ€å
        if sort_by == "news_time":
            order_clause = f"ORDER BY {sort_by} IS NULL, {sort_by} {'DESC' if order.lower() == 'desc' else 'ASC'}"
        else:
            order_clause = f"ORDER BY {sort_by} {'DESC' if order.lower() == 'desc' else 'ASC'}"

        # æŸ¥è¯¢æ€»æ•°
        from sqlalchemy import text
        count_sql = f"SELECT COUNT(*) FROM intelligence {where_clause}"
        count_result = await db.execute(text(count_sql), params)
        total = count_result.scalar() or 0

        print(f"ğŸ“Š æŸ¥è¯¢æ€»æ•°ç»“æœ: {total}")

        # åˆ†é¡µæŸ¥è¯¢
        offset = (page - 1) * page_size
        data_sql = f"""
            SELECT 
                id, title, summary, topic, news_time, collect_time, update_time,
                ai_score, score_dimensions, quality_status, is_merged, merged_count
            FROM intelligence 
            {where_clause} 
            {order_clause} 
            LIMIT :limit OFFSET :offset
        """

        params.update({
            'limit': page_size,
            'offset': offset
        })

        # æ‰§è¡ŒæŸ¥è¯¢
        result = await db.execute(text(data_sql), params)
        rows = result.fetchall()

        print(f"ğŸ“‹ æŸ¥è¯¢åˆ° {len(rows)} æ¡è®°å½•")

        # å®‰å…¨çš„æ—¶é—´æ ¼å¼åŒ–å‡½æ•°
        def safe_format_datetime(dt_value):
            """å®‰å…¨åœ°æ ¼å¼åŒ–æ—¶é—´å€¼"""
            if dt_value is None:
                return None

            # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
            if isinstance(dt_value, str):
                return dt_value

            # å¦‚æœæ˜¯datetimeå¯¹è±¡ï¼Œè½¬æ¢ä¸ºISOæ ¼å¼
            try:
                return dt_value.isoformat()
            except Exception as e:
                print(f"âš ï¸ æ—¶é—´æ ¼å¼åŒ–å¤±è´¥: {dt_value}, é”™è¯¯: {e}")
                return str(dt_value)

        # æ„å»ºå“åº”æ•°æ®
        items = []
        for row in rows:
            try:
                # æŸ¥è¯¢æ¥æº
                sources_result = await db.execute(
                    text("SELECT url, title FROM intelligence_sources WHERE intelligence_id = :id"),
                    {"id": row.id}
                )
                sources = []
                for s in sources_result.fetchall():
                    sources.append({"url": s.url, "title": s.title or ""})

                # è§£æJSONå­—æ®µ
                score_dimensions = {}
                if row.score_dimensions:
                    try:
                        import json
                        score_dimensions = json.loads(row.score_dimensions)
                    except Exception as json_error:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥ {row.id}: {json_error}")

                item = {
                    "id": row.id,
                    "title": row.title,
                    "summary": row.summary or "",
                    "news_time": safe_format_datetime(row.news_time),  # æ–°é—»æ—¶é—´
                    "collect_time": safe_format_datetime(row.collect_time),  # æ”¶é›†æ—¶é—´
                    "topic": row.topic or "",
                    "category": "å‰æ²¿èµ„è®¯",
                    "ai_score": float(row.ai_score or 0),
                    "dimensions": score_dimensions,
                    "quality_status": row.quality_status or "pending",
                    "competitors": [],
                    "sources": sources,
                    "is_merged": bool(row.is_merged),
                    "merged_count": int(row.merged_count or 0)
                }
                items.append(item)

            except Exception as item_error:
                print(f"âš ï¸ å¤„ç†è®°å½• {row.id} æ—¶å‡ºé”™: {item_error}")
                import traceback
                traceback.print_exc()
                continue

        print(f"âœ… æˆåŠŸæ„å»º {len(items)} æ¡è®°å½•")

        return {
            "items": items,
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": (total + page_size - 1) // page_size if total > 0 else 0
        }

    except Exception as e:
        print(f"âŒ æŸ¥è¯¢é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return {
            "items": [],
            "total": 0,
            "page": 1,
            "page_size": page_size,
            "total_pages": 0,
            "error": str(e)
        }


@pages_router.get("/partial/table", response_class=HTMLResponse)
async def get_intelligence_table(
        request: Request,
        db: AsyncSession = Depends(get_db),
        page: int = Query(1, ge=1),
        page_size: int = Query(20, ge=10, le=100),
        title: Optional[str] = Query(None),
        topic: Optional[str] = Query(None),
        quality: Optional[str] = Query(None),
        min_score: Optional[float] = Query(None),
        max_score: Optional[float] = Query(None),
        # æ·»åŠ æ–°é—»æ—¶é—´ç­›é€‰å‚æ•°
        news_start_date: Optional[str] = Query(None),
        news_end_date: Optional[str] = Query(None),
        sort_by: str = Query("news_time"),  # é»˜è®¤æŒ‰æ–°é—»æ—¶é—´æ’åº
        order: str = Query("desc")
):
    """è·å–æƒ…æŠ¥è¡¨æ ¼å±€éƒ¨è§†å›¾ - æ”¯æŒæ–°é—»æ—¶é—´ç­›é€‰"""
    try:
        print(f"ğŸ“Š è¡¨æ ¼è¯·æ±‚: page={page}, size={page_size}")
        print(f"ğŸ“… æ–°é—»æ—¶é—´ç­›é€‰: {news_start_date} åˆ° {news_end_date}")

        # æ˜¾å¼ä¼ é€’æ‰€æœ‰å‚æ•°ï¼Œé¿å…Queryå¯¹è±¡é—®é¢˜
        data = await get_intelligence_list(
            db=db,
            page=page,
            page_size=page_size,
            title=title,
            topic=topic,
            quality=quality,
            min_score=min_score,
            max_score=max_score,
            news_start_date=news_start_date,  # æ–°å¢
            news_end_date=news_end_date,  # æ–°å¢
            start_date=None,  # æ˜¾å¼ä¼ é€’None
            end_date=None,  # æ˜¾å¼ä¼ é€’None
            sort_by=sort_by,
            order=order
        )

        print(f"ğŸ“‹ è·å–æ•°æ®: total={data.get('total', 0)}, items={len(data.get('items', []))}")

        # ç”ŸæˆHTML
        html_content = generate_table_html(data)
        return HTMLResponse(content=html_content)

    except Exception as e:
        print(f"âŒ è¡¨æ ¼ç”Ÿæˆé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

        error_html = f"""
        <div class="intelligence-table-container">
            <div class="alert alert-danger m-4">
                <h5><i class="bi bi-exclamation-triangle"></i> åŠ è½½å¤±è´¥</h5>
                <p>é”™è¯¯: {str(e)}</p>
                <button class="btn btn-primary mt-2" onclick="loadTableData()">
                    <i class="bi bi-arrow-clockwise"></i> é‡è¯•
                </button>
            </div>
        </div>
        """
        return HTMLResponse(content=error_html, status_code=200)


# ä¿®å¤å¹¶å‘é—®é¢˜çš„æ‰¹é‡AIå¤„ç†
@api_router.post("/batch-ai-process")
async def batch_ai_process(
        db: AsyncSession = Depends(get_db),
        request_data: dict = Body(...)
):
    """æ‰¹é‡AIå¤„ç† - ä¿®å¤å¹¶å‘é—®é¢˜ç‰ˆæœ¬"""
    try:
        intelligence_ids = request_data.get("intelligence_ids", [])
        if not intelligence_ids:
            return {"status": "error", "message": "è¯·æä¾›è¦å¤„ç†çš„æƒ…æŠ¥IDåˆ—è¡¨"}

        print(f"ğŸš€ å¼€å§‹æ‰¹é‡AIåˆ†æ: {len(intelligence_ids)} æ¡æƒ…æŠ¥")

        # å…³é”®ä¿®å¤ï¼šä½¿ç”¨ä¸²è¡Œå¤„ç†è€Œä¸æ˜¯å¹¶å‘ï¼Œé¿å…sessionå†²çª
        results = []
        success_count = 0
        start_time = time.time()

        for idx, intel_id in enumerate(intelligence_ids, 1):
            try:
                print(f"ğŸ¤– å¤„ç†æƒ…æŠ¥ {intel_id} ({idx}/{len(intelligence_ids)})...")

                # ä¸ºæ¯ä¸ªAIå¤„ç†åˆ›å»ºç‹¬ç«‹çš„session
                ai_db = await get_ai_processing_db()
                try:
                    result = await ai_process_single_intelligence(intel_id, ai_db)
                    results.append({"id": intel_id, **result})

                    if result["status"] == "success":
                        success_count += 1
                        print(f"âœ… æƒ…æŠ¥ {intel_id} åˆ†ææˆåŠŸï¼Œè¯„åˆ†: {result.get('ai_score', 'N/A')}")
                    else:
                        print(f"âš ï¸ æƒ…æŠ¥ {intel_id} åˆ†æå¤±è´¥: {result['message']}")

                finally:
                    await ai_db.close()  # ç¡®ä¿sessionå…³é—­

                # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«è¯·æ±‚å¯¼è‡´é—®é¢˜
                if idx < len(intelligence_ids):
                    await asyncio.sleep(0.2)

            except Exception as e:
                print(f"âŒ æƒ…æŠ¥ {intel_id} å¤„ç†å¼‚å¸¸: {e}")
                results.append({
                    "id": intel_id,
                    "status": "error",
                    "message": f"å¤„ç†å¼‚å¸¸: {str(e)}"
                })

        total_time = time.time() - start_time
        print(f"ğŸ‰ æ‰¹é‡AIåˆ†æå®Œæˆ: æˆåŠŸ {success_count}/{len(intelligence_ids)} æ¡ï¼Œè€—æ—¶ {total_time:.2f}ç§’")

        return {
            "status": "success",
            "message": f"æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {len(intelligence_ids) - success_count} æ¡",
            "results": results,
            "success_count": success_count,
            "total_count": len(intelligence_ids),
            "processing_time": round(total_time, 2),
            "average_time": round(total_time / len(intelligence_ids), 2)
        }

    except Exception as e:
        print(f"âŒ æ‰¹é‡AIå¤„ç†å¤±è´¥: {e}")
        return {"status": "error", "message": f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}"}


async def ai_process_single_intelligence(
        intelligence_id: int,
        db: AsyncSession
):
    """å•ä¸ªæƒ…æŠ¥AIå¤„ç† - ä½¿ç”¨ç‹¬ç«‹session"""
    try:
        print(f"ğŸ¤– å¼€å§‹AIåˆ†ææƒ…æŠ¥ ID: {intelligence_id}")

        # ä½¿ç”¨åŸç”ŸSQLè·å–æƒ…æŠ¥å’Œæ¥æºï¼Œæå‡æ€§èƒ½
        from sqlalchemy import text
        result = await db.execute(
            text("""
                SELECT i.id, i.title, i.summary, i.topic, i.news_time, i.content,
                       s.url, s.title as source_title, s.domain
                FROM intelligence i
                LEFT JOIN intelligence_sources s ON i.id = s.intelligence_id
                WHERE i.id = :id
                LIMIT 1
            """),
            {"id": intelligence_id}
        )

        row = result.fetchone()
        if not row:
            return {"status": "error", "message": "æƒ…æŠ¥ä¸å­˜åœ¨"}

        # æ„å»ºNewsArticleå¯¹è±¡ï¼Œä½¿ç”¨æ”¹è¿›çš„æ—¶é—´å¤„ç†
        from services.ai_service import analyze_article_with_deepseek, NewsArticle

        # å®‰å…¨çš„æ—¶é—´å¤„ç†
        def safe_format_datetime(dt_value):
            if dt_value is None:
                return ""
            try:
                if isinstance(dt_value, str):
                    return dt_value
                elif hasattr(dt_value, 'isoformat'):
                    return dt_value.isoformat()
                else:
                    return str(dt_value)
            except Exception:
                return str(dt_value) if dt_value else ""

        article = NewsArticle(
            source=row.domain or "unknown",
            title=row.title,
            url=row.url or "",
            publish_date=safe_format_datetime(row.news_time),
            content=row.content or row.summary or row.title,  # ä¼˜å…ˆä½¿ç”¨content
            content_hash=""
        )

        print(f"ğŸ“„ å‡†å¤‡åˆ†ææ–‡ç« : {article.title[:50]}...")

        # è°ƒç”¨AIåˆ†æï¼Œå¢åŠ è¶…æ—¶æ§åˆ¶
        analysis = await asyncio.wait_for(
            analyze_article_with_deepseek(article),
            timeout=30  # 30ç§’è¶…æ—¶
        )

        print(f"ğŸ¯ AIåˆ†æå®Œæˆ")

        # è®¡ç®—ç»¼åˆè¯„åˆ† - ä½¿ç”¨æ–°çš„è¯„åˆ†ç»´åº¦
        scores = analysis.get("è¯„åˆ†è¯¦æƒ…", {})
        weights = {
            "æˆ˜ç•¥ç›¸å…³æ€§": 0.30,
            "è¡Œä¸šå½±å“åŠ›": 0.20,
            "æ—¶æ•ˆæ€§ç´§è¿«æ€§": 0.20,
            "ä¸šåŠ¡æœºä¼šé£é™©å¼ºåº¦": 0.15,
            "å¯æ“ä½œæ€§": 0.15
        }

        total_score = 0
        for dimension, weight in weights.items():
            score_data = scores.get(dimension, {})
            if isinstance(score_data, dict) and "åˆ†æ•°" in score_data:
                score_val = score_data["åˆ†æ•°"]
                total_score += score_val * weight
                print(f"ç»´åº¦ {dimension}: åˆ†æ•°={score_val}, æƒé‡={weight}, è´¡çŒ®={score_val * weight}")

        print(f"è®¡ç®—å¾—å‡ºçš„ç»¼åˆè¯„åˆ†: {total_score}")

        # æ›´æ–°æ•°æ®åº“
        import json
        await db.execute(
            text("""
                UPDATE intelligence 
                SET topic = :topic,
                    summary = :summary,
                    ai_score = :ai_score,
                    score_dimensions = :score_dimensions,
                    update_time = :update_time
                WHERE id = :id
            """),
            {
                "id": intelligence_id,
                "topic": analysis.get("è®®é¢˜", "æœªåˆ†ç±»"),
                "summary": analysis.get("æ‘˜è¦", row.title),
                "ai_score": round(total_score, 1),
                "score_dimensions": json.dumps(scores, ensure_ascii=False),
                "update_time": datetime.now().isoformat()
            }
        )

        await db.commit()

        print(f"âœ… AIåˆ†æå®Œæˆï¼Œè¯„åˆ†: {round(total_score, 1)}")

        return {
            "status": "success",
            "ai_score": round(total_score, 1),
            "dimensions": scores,
            "topic": analysis.get("è®®é¢˜"),
            "summary": analysis.get("æ‘˜è¦"),
            "category": analysis.get("ç±»åˆ«")
        }

    except asyncio.TimeoutError:
        print(f"â° AIåˆ†æè¶…æ—¶: æƒ…æŠ¥ {intelligence_id}")
        return {"status": "error", "message": "AIåˆ†æè¶…æ—¶"}
    except Exception as e:
        print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "message": f"AIåˆ†æå¤±è´¥: {str(e)}"}


@api_router.post("/{intelligence_id}/ai-process")
async def ai_process_intelligence(
        intelligence_id: int,
        db: AsyncSession = Depends(get_db)
):
    """å•æ¡æƒ…æŠ¥AIå¤„ç†"""
    return await ai_process_single_intelligence(intelligence_id, db)


@api_router.delete("/{intelligence_id}")
async def delete_intelligence(
        intelligence_id: int,
        db: AsyncSession = Depends(get_db)
):
    """åˆ é™¤æƒ…æŠ¥"""
    try:
        result = await db.execute(
            select(Intelligence).where(Intelligence.id == intelligence_id)
        )
        intelligence = result.scalar_one_or_none()

        if not intelligence:
            raise HTTPException(status_code=404, detail="æƒ…æŠ¥ä¸å­˜åœ¨")

        await db.delete(intelligence)
        await db.commit()

        return {"status": "success"}

    except Exception as e:
        return {"status": "error", "message": str(e)}


@api_router.get("/{intelligence_id}")
async def get_intelligence_detail(
        intelligence_id: int,
        db: AsyncSession = Depends(get_db)
):
    """è·å–æƒ…æŠ¥è¯¦æƒ…ï¼ˆç”¨äºç¼–è¾‘ï¼‰"""
    try:
        result = await db.execute(
            select(Intelligence).options(
                selectinload(Intelligence.sources),
                selectinload(Intelligence.competitors)
            ).where(Intelligence.id == intelligence_id)
        )
        intelligence = result.scalar_one_or_none()

        if not intelligence:
            raise HTTPException(status_code=404, detail="æƒ…æŠ¥ä¸å­˜åœ¨")

        return {
            "status": "success",
            "data": {
                "id": intelligence.id,
                "title": intelligence.title,
                "summary": intelligence.summary or "",
                "topic": intelligence.topic or "",
                "news_time": intelligence.news_time.isoformat() if intelligence.news_time else None,
                "quality_status": intelligence.quality_status,
                "ai_score": intelligence.ai_score,
                "sources": [{"url": s.url, "title": s.title} for s in intelligence.sources]
            }
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@api_router.put("/{intelligence_id}")
async def update_intelligence(
        intelligence_id: int,
        update_data: IntelligenceUpdate,
        db: AsyncSession = Depends(get_db)
):
    """æ›´æ–°æƒ…æŠ¥ä¿¡æ¯"""
    try:
        result = await db.execute(
            select(Intelligence).where(Intelligence.id == intelligence_id)
        )
        intelligence = result.scalar_one_or_none()

        if not intelligence:
            raise HTTPException(status_code=404, detail="æƒ…æŠ¥ä¸å­˜åœ¨")

        # æ›´æ–°å­—æ®µ
        for field, value in update_data.dict(exclude_unset=True).items():
            if hasattr(intelligence, field):
                setattr(intelligence, field, value)

        intelligence.update_time = datetime.now()

        await db.commit()
        return {"status": "success", "message": "æ›´æ–°æˆåŠŸ"}

    except Exception as e:
        await db.rollback()
        return {"status": "error", "message": str(e)}


@api_router.patch("/{intelligence_id}/quality")
async def update_quality_status(
        intelligence_id: int,
        status: str = Body(..., embed=True),
        db: AsyncSession = Depends(get_db)
):
    """æ›´æ–°è´¨é‡çŠ¶æ€"""
    try:
        # éªŒè¯çŠ¶æ€å€¼
        valid_statuses = ["pending", "approved", "rejected"]
        if status not in valid_statuses:
            return {"status": "error", "message": "æ— æ•ˆçš„çŠ¶æ€å€¼"}

        result = await db.execute(
            select(Intelligence).where(Intelligence.id == intelligence_id)
        )
        intelligence = result.scalar_one_or_none()

        if not intelligence:
            raise HTTPException(status_code=404, detail="æƒ…æŠ¥ä¸å­˜åœ¨")

        intelligence.quality_status = status
        intelligence.reviewed_at = datetime.now()

        await db.commit()
        return {"status": "success", "quality_status": status}

    except Exception as e:
        return {"status": "error", "message": str(e)}


def generate_table_html(data):
    """ç”Ÿæˆè¡¨æ ¼HTML - å®Œå…¨ä¿®å¤ç‰ˆ"""
    items = data.get("items", [])
    total = data.get("total", 0)
    page = data.get("page", 1)
    page_size = data.get("page_size", 20)
    total_pages = data.get("total_pages", 0)

    if not items:
        return """
        <div class="intelligence-table-container">
            <div class="empty-state text-center py-5">
                <i class="bi bi-inbox" style="font-size: 48px; color: #dee2e6;"></i>
                <p class="mt-3 text-muted">æš‚æ— æƒ…æŠ¥æ•°æ®</p>
                <small>ç‚¹å‡»"æ™ºèƒ½çˆ¬å–"å¼€å§‹æ”¶é›†æƒ…æŠ¥</small>
                <div class="mt-3">
                    <button class="btn btn-primary" onclick="openCrawlModal()">
                        <i class="bi bi-cloud-download"></i> å¼€å§‹çˆ¬å–
                    </button>
                </div>
            </div>
        </div>
        """

    # ç”Ÿæˆè¡¨æ ¼è¡Œ
    rows = []
    for item in items:
        # è·å–æ¥æºé“¾æ¥
        source_url = "#"
        if item.get('sources') and len(item['sources']) > 0:
            source_url = item['sources'][0].get('url', '#')

        # ä¿®å¤ï¼šä¼˜å…ˆæ˜¾ç¤ºæ–°é—»æ—¶é—´
        display_time = "-"
        if item.get('news_time'):
            try:
                from datetime import datetime
                time_str = item['news_time']
                if isinstance(time_str, str):
                    if 'T' in time_str:
                        dt = datetime.fromisoformat(time_str.replace('Z', ''))
                        display_time = dt.strftime('%Y-%m-%d')
                    else:
                        display_time = time_str[:10]
                else:
                    display_time = time_str.strftime('%Y-%m-%d')
            except Exception as e:
                print(f"æ–°é—»æ—¶é—´æ ¼å¼åŒ–é”™è¯¯: {e}")
                # å¤‡ç”¨ï¼šä½¿ç”¨æ”¶é›†æ—¶é—´
                if item.get('collect_time'):
                    try:
                        collect_str = item['collect_time']
                        if isinstance(collect_str, str) and 'T' in collect_str:
                            dt = datetime.fromisoformat(collect_str.replace('Z', ''))
                            display_time = dt.strftime('%Y-%m-%d')
                        else:
                            display_time = str(collect_str)[:10] if collect_str else "-"
                    except:
                        display_time = "-"

        # AIè¯„åˆ†è¯¦æƒ…
        score = float(item.get('ai_score', 0))
        score_class = 'success' if score >= 7 else 'warning' if score >= 5 else 'secondary'
        score_icon = 'star-fill' if score >= 7 else 'star-half' if score >= 5 else 'star'

        # æ„å»ºAIè¯„åˆ†tooltip
        dimensions = item.get('dimensions', {})
        tooltip_content = "æš‚æ— AIè¯„åˆ†è¯¦æƒ…"

        if dimensions:
            tooltip_parts = []
            business_impact = dimensions.get('ä¸šåŠ¡å½±å“', dimensions.get('business_impact', {}))
            if isinstance(business_impact, dict):
                score_val = business_impact.get('åˆ†æ•°', 0)
                reason = business_impact.get('ç†ç”±', '')[:100] + (
                    '...' if len(business_impact.get('ç†ç”±', '')) > 100 else '')
                tooltip_parts.append(f"ä¸šåŠ¡å½±å“: {score_val}/10 - {reason}")

            reliability = dimensions.get('å¯é æ€§', dimensions.get('reliability', {}))
            if isinstance(reliability, dict):
                score_val = reliability.get('åˆ†æ•°', 0)
                reason = reliability.get('ç†ç”±', '')[:100] + ('...' if len(reliability.get('ç†ç”±', '')) > 100 else '')
                tooltip_parts.append(f"å¯é æ€§: {score_val}/10 - {reason}")

            timeliness = dimensions.get('æ—¶æ•ˆæ€§', dimensions.get('timeliness', {}))
            if isinstance(timeliness, dict):
                score_val = timeliness.get('åˆ†æ•°', 0)
                reason = timeliness.get('ç†ç”±', '')[:100] + ('...' if len(timeliness.get('ç†ç”±', '')) > 100 else '')
                tooltip_parts.append(f"æ—¶æ•ˆæ€§: {score_val}/10 - {reason}")

            if tooltip_parts:
                tooltip_content = "\\n".join(tooltip_parts)

        tooltip_content = html.escape(tooltip_content).replace('"', '&quot;').replace("'", '&#39;')

        # çŠ¶æ€é…ç½®
        status = item.get('quality_status', 'pending')
        all_status_options = f"""
            <option value="pending" {'selected' if status == 'pending' else ''}>â³ å¾…å®¡æ ¸</option>
            <option value="approved" {'selected' if status == 'approved' else ''}>âœ… å·²é€šè¿‡</option>
            <option value="rejected" {'selected' if status == 'rejected' else ''}>âŒ å·²æ‹’ç»</option>
        """

        # ä¿®å¤ï¼šç«äº‰å¯¹æ‰‹è‡ªåŠ¨è¯†åˆ«å’Œæ‰‹åŠ¨æ ‡è®°
        competitors = item.get('competitors', [])
        competitor_badge = ""
        title_lower = item['title'].lower()
        summary_lower = (item.get('summary', '') or '').lower()

        # è‡ªåŠ¨è¯†åˆ«ç«äº‰å¯¹æ‰‹å…³é”®è¯
        competitor_keywords = [
            'ç«äº‰', 'å¯¹æ‰‹', 'åŒè¡Œ', 'ç«å“', 'competitor', 'rival',
            'æŒ‘æˆ˜', 'challenge', 'è¶…è¶Š', 'é¢†å…ˆ', 'å¸‚åœºä»½é¢'
        ]
        is_competitor = any(keyword in title_lower or keyword in summary_lower for keyword in competitor_keywords)

        if is_competitor or len(competitors) > 0:
            competitor_badge = f'''
                <span class="badge bg-danger ms-1" onclick="toggleCompetitor({item['id']})" 
                      style="cursor: pointer;" title="ç‚¹å‡»å–æ¶ˆç«äº‰å¯¹æ‰‹æ ‡è®°">
                    ğŸ”´ ç«äº‰å¯¹æ‰‹
                </span>
            '''
        else:
            # æ·»åŠ æ ‡è®°ä¸ºç«äº‰å¯¹æ‰‹çš„æŒ‰é’®
            competitor_badge = f'''
                <span class="badge bg-outline-secondary ms-1" onclick="toggleCompetitor({item['id']})" 
                      style="cursor: pointer; border: 1px dashed #ccc; color: #666;" 
                      title="ç‚¹å‡»æ ‡è®°ä¸ºç«äº‰å¯¹æ‰‹">
                    â• æ ‡è®°ç«äº‰å¯¹æ‰‹
                </span>
            '''

        # è®®é¢˜å’Œç±»åˆ«
        topic = html.escape(item.get('topic', 'æœªåˆ†ç±»'))
        category = html.escape(item.get('category', 'å‰æ²¿èµ„è®¯'))

        # æ‘˜è¦å¤„ç† - é™åˆ¶é•¿åº¦é¿å…ç•Œé¢æ··ä¹±
        summary = item.get('summary', '')
        if summary and summary.strip():
            display_summary = summary[:150] + ('...' if len(summary) > 150 else '')
        else:
            display_summary = item['title'][:80] + ('...' if len(item['title']) > 80 else '')

        display_summary = html.escape(display_summary)

        # æ„å»ºè¡¨æ ¼è¡Œ - ä¿®å¤åˆ—ç»“æ„
        row = f"""
        <tr data-id="{item['id']}" class="intelligence-row">
            <td class="text-center checkbox-col">
                <input type="checkbox" class="form-check-input intelligence-checkbox" 
                       value="{item['id']}" onchange="toggleRowSelection({item['id']}, this)">
            </td>
            <td class="title-col">
                <div class="title-wrapper">
                    <a href="{html.escape(source_url)}" target="_blank" class="text-decoration-none intelligence-title-link">
                        <strong class="text-primary">{html.escape(item['title'][:60])}{'...' if len(item['title']) > 60 else ''}</strong>
                    </a>
                    {f'<div class="text-muted small mt-1 intelligence-summary">{display_summary}</div>' if display_summary else ''}
                    <div class="mt-2 intelligence-badges">
                        <span class="badge bg-primary me-1">{topic}</span>
                        <span class="badge bg-info me-1">{category}</span>
                        {competitor_badge}
                        {f'<span class="badge bg-warning">åˆå¹¶{item["merged_count"]}æ¡</span>' if item.get('is_merged') else ''}
                    </div>
                </div>
            </td>
            <td class="text-center time-col">
                <small class="text-muted">{display_time}</small>
            </td>
            <td class="text-center score-col">
                <div class="score-container">
                    <i class="bi bi-{score_icon} text-{score_class} me-1"></i>
                    <span class="badge bg-{score_class} ai-score-badge cursor-help" 
                          data-bs-toggle="tooltip" 
                          data-bs-placement="top"
                          data-bs-html="true"
                          title="{tooltip_content}">{score:.1f}</span>
                </div>
            </td>
            <td class="status-col">
                <select class="form-select form-select-sm status-select" 
                        onchange="updateQualityStatus({item['id']}, this.value)"
                        data-current="{status}">
                    {all_status_options}
                </select>
            </td>
            <td class="text-center actions-col">
                <div class="btn-group-custom" role="group">
                    <button type="button" class="btn btn-outline-primary btn-sm btn-action" 
                            onclick="viewDetails({item['id']})" 
                            title="æŸ¥çœ‹è¯¦æƒ…"
                            data-bs-toggle="tooltip">
                        <i class="bi bi-eye"></i>
                    </button>
                    <button type="button" class="btn btn-outline-success btn-sm btn-action" 
                            onclick="aiProcess({item['id']})" 
                            title="AIé‡æ–°åˆ†æ"
                            data-bs-toggle="tooltip">
                        <i class="bi bi-robot"></i>
                    </button>
                    <button type="button" class="btn btn-outline-warning btn-sm btn-action" 
                            onclick="editIntelligence({item['id']})" 
                            title="ç¼–è¾‘"
                            data-bs-toggle="tooltip">
                        <i class="bi bi-pencil"></i>
                    </button>
                    <button type="button" class="btn btn-outline-danger btn-sm btn-action" 
                            onclick="deleteIntelligence({item['id']})" 
                            title="åˆ é™¤"
                            data-bs-toggle="tooltip">
                        <i class="bi bi-trash"></i>
                    </button>
                </div>
            </td>
        </tr>
        """
        rows.append(row)

    # ä¿®å¤ï¼šæ‰¹é‡æ“ä½œå·¥å…·æ  - ä¿®å¤å¯¼å‡ºä¸‹æ‹‰é—®é¢˜
    batch_toolbar = """
    <div class="batch-operations bg-light p-3 border-bottom">
        <div class="d-flex flex-wrap align-items-center justify-content-between">
            <div class="batch-actions-left d-flex flex-wrap align-items-center">
                <span class="me-3 fw-bold">æ‰¹é‡æ“ä½œ:</span>
                <button class="btn btn-success btn-sm me-2 mb-1 batch-btn" onclick="batchAIProcess()">
                    <i class="bi bi-robot"></i> æ‰¹é‡AIåˆ†æ
                </button>
                <button class="btn btn-primary btn-sm me-2 mb-1 batch-btn" onclick="batchApprove()">
                    <i class="bi bi-check-circle"></i> æ‰¹é‡é€šè¿‡
                </button>
                <button class="btn btn-warning btn-sm me-2 mb-1 batch-btn" onclick="batchReject()">
                    <i class="bi bi-x-circle"></i> æ‰¹é‡æ‹’ç»
                </button>
                

                <!-- ä¿®å¤ï¼šå¯¼å‡ºæŒ‰é’®ç»„ - ç§»é™¤é‡å¤ä¸‹æ‹‰ç®­å¤´ -->
                <div class="btn-group me-2 mb-1">
                    <button class="btn btn-info btn-sm batch-btn" onclick="exportSelected('csv')">
                        <i class="bi bi-download"></i> å¯¼å‡ºé€‰ä¸­
                    </button>
                    <button class="btn btn-info btn-sm dropdown-toggle dropdown-toggle-split" 
                            data-bs-toggle="dropdown" 
                            aria-expanded="false">
                        <span class="visually-hidden">æ›´å¤šå¯¼å‡ºé€‰é¡¹</span>
                    </button>
                    <ul class="dropdown-menu">
                        <li><h6 class="dropdown-header">å¯¼å‡ºé€‰ä¸­é¡¹</h6></li>
                        <li><a class="dropdown-item" href="#" onclick="exportSelected('csv')">
                            <i class="bi bi-filetype-csv"></i> å¯¼å‡ºé€‰ä¸­ä¸ºCSV
                        </a></li>
                        <li><a class="dropdown-item" href="#" onclick="exportSelected('json')">
                            <i class="bi bi-filetype-json"></i> å¯¼å‡ºé€‰ä¸­ä¸ºJSON
                        </a></li>
                        <li><hr class="dropdown-divider"></li>
                        <li><h6 class="dropdown-header">å¯¼å‡ºç­›é€‰ç»“æœ</h6></li>
                        <li><a class="dropdown-item" href="#" onclick="exportFiltered('csv')">
                            <i class="bi bi-funnel"></i> å¯¼å‡ºå½“å‰ç­›é€‰ç»“æœ(CSV)
                        </a></li>
                        <li><a class="dropdown-item" href="#" onclick="exportFiltered('json')">
                            <i class="bi bi-funnel"></i> å¯¼å‡ºå½“å‰ç­›é€‰ç»“æœ(JSON)
                        </a></li>
                        <li><hr class="dropdown-divider"></li>
                        <li><a class="dropdown-item" href="#" onclick="exportAll('csv')">
                            <i class="bi bi-collection"></i> å¯¼å‡ºå…¨éƒ¨æ•°æ®(CSV)
                        </a></li>
                        <li><a class="dropdown-item" href="#" onclick="downloadTemplate()">
                            <i class="bi bi-file-earmark"></i> ä¸‹è½½å¯¼å…¥æ¨¡æ¿
                        </a></li>
                    </ul>
                </div>

                <button class="btn btn-danger btn-sm me-2 mb-1 batch-btn" onclick="batchDelete()">
                    <i class="bi bi-trash"></i> æ‰¹é‡åˆ é™¤
                </button>
                <button class="btn btn-warning btn-sm me-2 mb-1 batch-btn" onclick="batchExtractDatesForSelected()">
                    <i class="bi bi-calendar-plus"></i> ä¸ºé€‰ä¸­é¡¹è¡¥å…¨æ—¥æœŸ
                </button>
            </div>
            <div class="batch-count-right">
                <span id="selectedCount" class="text-muted">å·²é€‰æ‹© 0 é¡¹</span>
            </div>
        </div>
    </div>
    """

    # åˆ†é¡µ
    pagination = f"""
    <div class="d-flex justify-content-between align-items-center p-3 bg-light border-top">
        <div>
            <span>å…± <strong>{total}</strong> æ¡è®°å½•ï¼Œç¬¬ <strong>{page}</strong> é¡µï¼Œå…± <strong>{total_pages}</strong> é¡µ</span>
        </div>
        <div class="d-flex align-items-center">
            <label class="me-2">æ¯é¡µ:</label>
            <select class="form-select form-select-sm me-3" style="width: 80px;" onchange="changePageSize(this.value)">
                <option value="10" {'selected' if page_size == 10 else ''}>10</option>
                <option value="20" {'selected' if page_size == 20 else ''}>20</option>
                <option value="50" {'selected' if page_size == 50 else ''}>50</option>
                <option value="100" {'selected' if page_size == 100 else ''}>100</option>
            </select>
            <nav>
                <ul class="pagination pagination-sm mb-0">
                    <li class="page-item {'disabled' if page == 1 else ''}">
                        <a class="page-link" href="#" onclick="{'loadPage(' + str(page - 1) + ')' if page > 1 else 'return false;'}">
                            <i class="bi bi-chevron-left"></i>
                        </a>
                    </li>
                    <li class="page-item active">
                        <span class="page-link">{page}</span>
                    </li>
                    <li class="page-item {'disabled' if page >= total_pages else ''}">
                        <a class="page-link" href="#" onclick="{'loadPage(' + str(page + 1) + ')' if page < total_pages else 'return false;'}">
                            <i class="bi bi-chevron-right"></i>
                        </a>
                    </li>
                </ul>
            </nav>
        </div>
    </div>
    """

    # å®Œæ•´HTML - åŒ…å«æ‰€æœ‰æ ·å¼å’ŒJS
    html_content = f"""
    <div class="intelligence-table-container">
        {batch_toolbar}

        <div class="table-responsive">
            <table class="table table-hover table-sm mb-0 intelligence-table">
                <thead class="table-light sticky-top">
                    <tr>
                        <th class="text-center checkbox-col">
                            <input type="checkbox" class="form-check-input" id="selectAll" 
                                   onchange="toggleSelectAll(this)">
                        </th>
                        <th class="title-col">æ ‡é¢˜ / æ‘˜è¦ / æ ‡ç­¾</th>
                        <th class="text-center time-col">æ–°é—»æ—¶é—´</th>
                        <th class="text-center score-col">AIè¯„åˆ†</th>
                        <th class="text-center status-col">å®¡æ ¸çŠ¶æ€</th>
                        <th class="text-center actions-col">æ“ä½œ</th>
                    </tr>
                </thead>
                <tbody>
                    {''.join(rows)}
                </tbody>
            </table>
        </div>

        {pagination}
    </div>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-icons/1.10.0/font/bootstrap-icons.min.css" rel="stylesheet">

    <style>
    /* ä¿®å¤å¯¼å‡ºæŒ‰é’®æ ·å¼ - è§£å†³åŒä¸‹æ‹‰é—®é¢˜ */
    .batch-operations .btn-group {{
        position: relative;
    }}

    .batch-operations .btn-group .dropdown-toggle-split {{
        border-left: 1px solid rgba(255,255,255,0.2);
        padding-left: 6px !important;
        padding-right: 6px !important;
    }}

    .batch-operations .dropdown-menu {{
        z-index: 1050;
        min-width: 250px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }}

    .batch-operations .dropdown-item {{
        padding: 8px 16px;
        font-size: 13px;
        display: flex;
        align-items: center;
        gap: 8px;
    }}

    .batch-operations .dropdown-header {{
        font-size: 11px;
        font-weight: 600;
        color: #6c757d;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }}

    /* æ‰¹é‡æ“ä½œæ å¸ƒå±€ä¿®å¤ */
    .batch-operations {{
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-bottom: 2px solid #dee2e6;
        padding: 12px 20px;
    }}

    .batch-actions-left {{
        flex: 1;
        min-width: 0;
    }}

    .batch-count-right {{
        flex-shrink: 0;
        margin-left: 16px;
    }}

    /* ä¿®å¤æ‰¹é‡æŒ‰é’®æ ·å¼ */
    .batch-btn {{
        font-size: 13px !important;
        padding: 6px 12px !important;
        border-radius: 6px !important;
        font-weight: 500 !important;
        border: 1px solid transparent !important;
        transition: all 0.2s ease !important;
        white-space: nowrap !important;
        display: inline-flex !important;
        align-items: center !important;
        gap: 4px !important;
    }}

    .batch-btn:hover {{
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 6px rgba(0,0,0,0.15) !important;
    }}

    /* ç«äº‰å¯¹æ‰‹æ ‡è®°æ ·å¼ */
    .badge[onclick] {{
        cursor: pointer !important;
        transition: all 0.2s ease !important;
    }}

    .badge[onclick]:hover {{
        transform: scale(1.05) !important;
        box-shadow: 0 2px 4px rgba(0,0,0,0.2) !important;
    }}

    /* è¡¨æ ¼å¸ƒå±€ä¿®å¤ */
    .intelligence-table {{
        table-layout: fixed;
        width: 100%;
    }}

    .checkbox-col {{ width: 50px; }}
    .title-col {{ width: 40%; }}
    .time-col {{ width: 120px; }}
    .score-col {{ width: 100px; }}
    .status-col {{ width: 130px; }}
    .actions-col {{ width: 200px; }}

    /* æ ‡é¢˜åˆ—å†…å®¹å¤„ç† */
    .title-wrapper {{
        max-width: 100%;
        overflow: hidden;
    }}

    .intelligence-title-link strong {{
        display: block;
        overflow: hidden;
        text-overflow: ellipsis;
        white-space: nowrap;
    }}

    .intelligence-summary {{
        font-size: 12px;
        line-height: 1.3;
        color: #6c757d;
        margin-top: 4px;
        display: -webkit-box;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
        overflow: hidden;
    }}

    /* çŠ¶æ€é€‰æ‹©æ¡†ä¿®å¤ */
    .status-select {{
        font-size: 12px !important;
        padding: 4px 8px !important;
        border: 1px solid #e5e7eb !important;
        border-radius: 4px !important;
        background-color: white !important;
        width: 100% !important;
        appearance: menulist !important;
    }}

    .status-select:focus {{
        border-color: #667eea !important;
        box-shadow: 0 0 0 2px rgba(102, 126, 234, 0.1) !important;
        outline: none !important;
    }}

    /* ç§»åŠ¨ç«¯é€‚é… */
    @media (max-width: 768px) {{
        .batch-operations .d-flex {{
            flex-direction: column;
            gap: 12px;
            align-items: stretch !important;
        }}

        .batch-actions-left {{
            justify-content: center;
        }}

        .batch-count-right {{
            text-align: center;
            margin-left: 0;
        }}

        .intelligence-table {{
            min-width: 900px;
        }}
    }}
    </style>

    <script>
    document.addEventListener('DOMContentLoaded', function() {{
        // åˆå§‹åŒ–å·¥å…·æç¤º
        var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'));
        var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {{
            return new bootstrap.Tooltip(tooltipTriggerEl, {{
                html: true,
                container: 'body',
                sanitize: false,
                delay: {{ show: 500, hide: 100 }},
                placement: 'top'
            }});
        }});

        console.log('è¡¨æ ¼HTMLåŠ è½½å®Œæˆï¼Œå·¥å…·æç¤ºå·²åˆå§‹åŒ–');
        updateSelectedCount();
    }});

    function updateSelectedCount() {{
        const selected = document.querySelectorAll('.intelligence-checkbox:checked').length;
        const counter = document.getElementById('selectedCount');
        if (counter) {{
            counter.textContent = `å·²é€‰æ‹© ${{selected}} é¡¹`;
        }}

        const selectAll = document.getElementById('selectAll');
        const totalCheckboxes = document.querySelectorAll('.intelligence-checkbox').length;
        if (selectAll) {{
            selectAll.checked = selected === totalCheckboxes && totalCheckboxes > 0;
            selectAll.indeterminate = selected > 0 && selected < totalCheckboxes;
        }}
    }}

    // ç«äº‰å¯¹æ‰‹æ ‡è®°åˆ‡æ¢å‡½æ•°
    async function toggleCompetitor(intelligenceId) {{
        try {{
            const response = await fetch(`/api/intelligence/${{intelligenceId}}/toggle-competitor`, {{
                method: 'POST',
                headers: {{
                    'Content-Type': 'application/json',
                }}
            }});

            const result = await response.json();
            if (result.status === 'success') {{
                showAlert(result.message, 'success');
                loadTableData(); // é‡æ–°åŠ è½½è¡¨æ ¼
            }} else {{
                showAlert('æ“ä½œå¤±è´¥: ' + result.message, 'danger');
            }}
        }} catch (error) {{
            showAlert('æ“ä½œå¤±è´¥: ' + error.message, 'danger');
        }}
    }}

    window.updateSelectedCount = updateSelectedCount;
    window.toggleCompetitor = toggleCompetitor;
    </script>
    """

    return html_content


# æ·»åŠ ç«äº‰å¯¹æ‰‹åˆ‡æ¢çš„APIè·¯ç”±
@api_router.post("/{intelligence_id}/toggle-competitor")
async def toggle_competitor_status(
        intelligence_id: int,
        db: AsyncSession = Depends(get_db)
):
    """åˆ‡æ¢æƒ…æŠ¥çš„ç«äº‰å¯¹æ‰‹æ ‡è®°çŠ¶æ€"""
    try:
        result = await db.execute(
            select(Intelligence).where(Intelligence.id == intelligence_id)
        )
        intelligence = result.scalar_one_or_none()

        if not intelligence:
            raise HTTPException(status_code=404, detail="æƒ…æŠ¥ä¸å­˜åœ¨")

        # ç®€å•çš„ç«äº‰å¯¹æ‰‹æ ‡è®°é€»è¾‘ï¼šä½¿ç”¨ä¸€ä¸ªå­—æ®µå­˜å‚¨
        # è¿™é‡Œå‡è®¾æœ‰ä¸€ä¸ª is_competitor å­—æ®µï¼Œå¦‚æœæ²¡æœ‰å¯ä»¥æ·»åŠ åˆ°æ¨¡å‹ä¸­
        # æˆ–è€…ä½¿ç”¨ç°æœ‰çš„å­—æ®µå­˜å‚¨è¿™ä¸ªä¿¡æ¯

        # ä¸´æ—¶æ–¹æ¡ˆï¼šåœ¨ score_dimensions ä¸­å­˜å‚¨ç«äº‰å¯¹æ‰‹ä¿¡æ¯
        score_dimensions = {}
        if intelligence.score_dimensions:
            try:
                import json
                score_dimensions = json.loads(intelligence.score_dimensions)
            except:
                score_dimensions = {}

        # åˆ‡æ¢ç«äº‰å¯¹æ‰‹çŠ¶æ€
        is_competitor = score_dimensions.get('is_competitor', False)
        score_dimensions['is_competitor'] = not is_competitor

        intelligence.score_dimensions = json.dumps(score_dimensions, ensure_ascii=False)
        intelligence.update_time = datetime.now()

        await db.commit()

        status_text = "å·²æ ‡è®°ä¸ºç«äº‰å¯¹æ‰‹" if not is_competitor else "å·²å–æ¶ˆç«äº‰å¯¹æ‰‹æ ‡è®°"

        return {
            "status": "success",
            "message": status_text,
            "is_competitor": not is_competitor
        }

    except Exception as e:
        await db.rollback()
        return {"status": "error", "message": str(e)}


# ===== é¡µé¢è·¯ç”± =====

@pages_router.get("/", response_class=HTMLResponse)
async def intelligence_page(request: Request):
    """æƒ…æŠ¥ç®¡ç†ä¸»é¡µé¢"""
    return templates.TemplateResponse("intelligence.html", {"request": request})